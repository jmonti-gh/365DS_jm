{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 Data Manipulation with NumPy\n",
    "- Examine how to clean and preprocess data using NumPy.\n",
    "- Hoy to discover missing values (and fill them up).\n",
    "- Ways to remove irrelevant data.\n",
    "- sort(), shuffle(), reshape(), stack(), strip()\n",
    "## 8_11 Stacking NDarrays\n",
    "- stack(), vstack() - vert, hstack() - horizon, dstack() - depth\n",
    "- We can just stack arrays of matching shapes to create a larger array: a \"stack\" (of arrays)\n",
    "- The arrays MUST be the same shape in the axis that you stack: vstack ->same num of cols, hstack -> same num of rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### numpy.stack(arrays, axis=0, out=None, *, dtype=None, casting='same_kind')\n",
    "- Join a sequence of arrays along a new axis.\n",
    "- The axis parameter specifies the index of the new axis in the dimensions of the result. For example, if axis=0 it will be the first dimension and if axis=-1 it will be the last dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### numpy.vstack(tup, *, dtype=None, casting='same_kind')\n",
    "- Stack arrays in sequence vertically (row wise).\n",
    "- This is equivalent to concatenation along the first axis after 1-D arrays of shape (N,) have been reshaped to (1,N). Rebuilds arrays divided by vsplit.\n",
    "- This function makes most sense for arrays with up to 3 dimensions. For instance, for pixel-data with a height (first axis), width (second axis), and r/g/b channels (third axis). The functions concatenate, stack and block provide more general stacking and concatenation operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### numpy.hstack(tup, *, dtype=None, casting='same_kind')\n",
    "- Stack arrays in sequence horizontally (column wise).\n",
    "- This is equivalent to concatenation along the second axis, except for 1-D arrays where it concatenates along the first axis. Rebuilds arrays divided by hsplit.\n",
    "- This function makes most sense for arrays with up to 3 dimensions. For instance, for pixel-data with a height (first axis), width (second axis), and r/g/b channels (third axis). The functions concatenate, stack and block provide more general stacking and concatenation operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### numpy.dstack(tup)\n",
    "- Stack arrays in sequence depth wise (along third axis).\n",
    "- This is equivalent to concatenation along the third axis after 2-D arrays of shape (M,N) have been reshaped to (M,N,1) and 1-D arrays of shape (N,) have been reshaped to (1,N,1). Rebuilds arrays divided by dsplit.\n",
    "- This function makes most sense for arrays with up to 3 dimensions. For instance, for pixel-data with a height (first axis), width (second axis), and r/g/b channels (third axis). The functions concatenate, stack and block provide more general stacking and concatenation operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.__version__\n",
    "np.set_printoptions(suppress=True)  # To avoid scientific notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function show_attr\n",
    "\n",
    "def show_attr(arrnm: str) -> str:\n",
    "    strout = f' {arrnm}: '\n",
    "\n",
    "    for attr in ('shape', 'ndim', 'size', 'dtype'):     #, 'itemsize'):\n",
    "            arrnm_attr = arrnm + '.' + attr\n",
    "            strout += f'| {attr}: {eval(arrnm_attr)} '\n",
    "\n",
    "    return strout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two Datasets (arrays) we are going to use \n",
    "1. lend_num: Lending-Company-Numeric-Data.csv, without NANs and don´t need preprocessing\n",
    "2. lend_pre: Lending-Company-Numeric-Data-NAN.csv, whith NANs that will need preprocessing to replace the missing vals by the mean val of each column. five ways i know to do this\n",
    "    1. The way we learn in 8_2 Substituting Missing Values in NDarryas, which requires reading the file twice, whose steps are:\n",
    "        1. np.genfromtext the .csv whit only the delimite= option (data will contain NANS)\n",
    "        2. Calc np.nanmax (or nanmin) and store in orig_max\n",
    "        3. Store in temp_max_plus1 = temp_max + 1\n",
    "        4. Calc np.nammean(data, axis=0) for each col and store in original_means 1-D array\n",
    "        5. Reread with genfromtxt the same .csv with delimiter= and fillnig_value=temp_max_plus1 \n",
    "        6. Using np.where replace in each col the value of temp_max_plus1 by original_mean of this column\n",
    "    2. The way we learn in 8_7 Argument Where in NumPy, don't need to read the .csv twice.\n",
    "        1. np.genfromtext the .csv whit only the delimite= option (data will contain NANS)\n",
    "        2. Calc np.nammean(data, axis=0) for each col and store in original_means 1-D array\n",
    "        2. np.argwhere(np.isnan(data)) will give us the coordinates of NANs for each column\n",
    "        3. In a for loop assing the corresponding mean to each column\n",
    "    3. Same as 2. but using np.nonzero, which saves us from using the for loop and allows everything to be more direct since the output tuple of np.nonzeo allows indexing the ndarrays directly.\n",
    "    4. np.where(np.isnan( ), mean, )\n",
    "    5. np.where(np.nan_to_num(), mean, )\n",
    "- I will use 2. np.argwhere()\n",
    "\n",
    "> At the end of this notebook I will display these three methods under the title __'5 methods to replace missing values.'__\n",
    "> FUTURE!, make de time comparative of 5 methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [ 2000.,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' lend_num: | shape: (1043, 6) | ndim: 2 | size: 6258 | dtype: float64 '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st dataset - lend_num, original without NANs\n",
    "lend_num = np.loadtxt('Lending-Company-Numeric-Data.csv', delimiter=',')\n",
    "display(lend_num)\n",
    "show_attr('lend_num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [   nan,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NANs: 260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2000.  ,    40.  ,   365.  ,  3121.  ,  4241.  , 13621.  ],\n",
       "       [ 2000.  ,    40.  ,   365.  ,  3061.  ,  4171.  , 15041.  ],\n",
       "       [ 1000.  ,    40.  ,   365.  ,  2160.  ,  3280.  , 15340.  ],\n",
       "       ...,\n",
       "       [ 2250.25,    40.  ,   365.  ,  4201.  ,  5001.  , 16600.  ],\n",
       "       [ 1000.  ,    40.  ,   365.  ,  2080.  ,  3320.  , 15600.  ],\n",
       "       [ 2000.  ,    40.  ,   365.  ,  4601.  ,  4601.  , 16600.  ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NANs: 0\n",
      "Original Means == Actual Means: True\n"
     ]
    }
   ],
   "source": [
    "# 2st dataset - lend_pre, original without NANs\n",
    "lend_pre = np.genfromtxt('Lending-Company-Numeric-Data-NAN.csv', delimiter=';')\n",
    "display(lend_pre)\n",
    "show_attr('lend_pre')\n",
    "print('Number of NANs:', np.isnan(lend_pre).sum())\n",
    "\n",
    "# Process to replace NANs w/mean of each column\n",
    "orig_means = np.nanmean(lend_pre, axis=0).round(2)  # Means of all columns\n",
    "nan_ixs = np.argwhere(np.isnan(lend_pre))   # Indices of NANs \n",
    "for nan_ix in nan_ixs:                      # for e/NAN (couple of indices)\n",
    "    # Change the NAN to the mean of its column \n",
    "    lend_pre[nan_ix[0], nan_ix[1]] = orig_means[nan_ix[1]]\n",
    "\n",
    "# DONE, check the results\n",
    "display(lend_pre)\n",
    "show_attr('lend_pre')\n",
    "print('Number of NANs:', np.isnan(lend_pre).sum())\n",
    "means = np.mean(lend_pre, axis=0).round(2)          # Actual means\n",
    "print('Original Means == Actual Means:', np.array_equal(orig_means, means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2000., 2000., 1000., ..., 2000., 1000., 2000.],\n",
       "       [  40.,   40.,   40., ...,   40.,   40.,   40.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' stck_1: | shape: (2, 1043) | ndim: 2 | size: 2086 | dtype: float64 '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an array with the first two cols of lend_num\n",
    "stck_1 = np.stack((lend_num[:,0], lend_num[:,1]))\n",
    "display(stck_1)\n",
    "show_attr('stck_1')     # Two rows 1043 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2000., 2000., 1000., ..., 2000., 1000., 2000.],\n",
       "       [  40.,   40.,   40., ...,   40.,   40.,   40.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same as tansposing the first two cols of lend_num\n",
    "np.transpose(lend_num[:,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2000., 2000., 1000., ..., 2000., 1000., 2000.],\n",
       "       [  40.,   40.,   40., ...,   40.,   40.,   40.],\n",
       "       [ 365.,  365.,  365., ...,  365.,  365.,  365.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[2000., 2000., 1000., ..., 2000., 1000., 2000.],\n",
       "       [  40.,   40.,   40., ...,   40.,   40.,   40.],\n",
       "       [ 365.,  365.,  365., ...,  365.,  365.,  365.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# More than two columns - Stacking them on top of one another\n",
    "display(np.stack((lend_num[:,0], lend_num[:,1], lend_num[:,2])))\n",
    "np.transpose(lend_num[:,:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   40.,    40.,    40., ...,    40.,    40.,    40.],\n",
       "       [ 2000.,  2000.,  1000., ...,  2000.,  1000.,  2000.],\n",
       "       [13621., 15041., 15340., ..., 16600., 15600., 16600.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack in different order and mix with others (transpose can´t)\n",
    "np.stack((lend_num[:,1], lend_num[:,0], lend_num[:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  40., 2000.],\n",
       "       [  40., 2000.],\n",
       "       [  40., 1000.],\n",
       "       ...,\n",
       "       [  40., 2000.],\n",
       "       [  40., 1000.],\n",
       "       [  40., 2000.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' stck_2: | shape: (1043, 2) | ndim: 2 | size: 2086 | dtype: float64 '"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To stack the columns Side by Side, use axis=1\n",
    "stck_2 = np.stack((lend_num[:,1], lend_num[:,0]), axis=1)\n",
    "display(stck_2)\n",
    "show_attr('stck_2')     # Two rows 1043 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.  ,    40.  ,   365.  ,  3121.  ,  4241.  , 13621.  ],\n",
       "       [ 2000.  ,    40.  ,   365.  ,  3061.  ,  4171.  , 15041.  ],\n",
       "       [ 1000.  ,    40.  ,   365.  ,  2160.  ,  3280.  , 15340.  ],\n",
       "       ...,\n",
       "       [ 2250.25,    40.  ,   365.  ,  4201.  ,  5001.  , 16600.  ],\n",
       "       [ 1000.  ,    40.  ,   365.  ,  2080.  ,  3320.  , 15600.  ],\n",
       "       [ 2000.  ,    40.  ,   365.  ,  4601.  ,  4601.  , 16600.  ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' stck_3: | shape: (2086, 6) | ndim: 2 | size: 12516 | dtype: float64 '"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.vstack() = vertical stack, of two arrays of the same shape\n",
    "# Stacks 2-D arrays (and 1-D array) vertically\n",
    "# Places the first array on top of the second one, results in a longer array\n",
    "stck_3 = np.vstack((lend_num, lend_pre))\n",
    "display(stck_3)\n",
    "show_attr('stck_3')     # 2086 (1043 x 2) rows, 6 cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3121.,  4241., 13621.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' stck_3: | shape: (2, 6) | ndim: 2 | size: 12 | dtype: float64 '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vstacking 1-D arrays\n",
    "display(lend_pre[0].ndim)\n",
    "stck_3 = np.vstack((lend_num[0], lend_pre[0]))\n",
    "display(stck_3)\n",
    "show_attr('stck_3')     # Two rows, six columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3260., 13740.],\n",
       "       [ 2000.,    40.,   365.,  4081.,  4681., 13841.],\n",
       "       [ 1000.,    40.,   365.,  1960.,  2880., 11540.],\n",
       "       [ 1000.,    40.,   365.,  2200.,  4600., 15600.],\n",
       "       [ 2000.,    40.,   365.,  3201.,  4321., 16600.],\n",
       "       [ 2500.,    50.,   365.,  3250.,  4750., 20750.],\n",
       "       [ 2000.,    50.,   365.,  3400.,  5000., 20250.],\n",
       "       [ 2000.,    40.,   365.,  4201.,  5001., 16600.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lend_num_smll: | shape: (9, 6) | ndim: 2 | size: 54 | dtype: float64 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       [ 2000.,    40.,   365.,  3041.,  4241., 15321.],\n",
       "       [ 2000.,    50.,   365.,  3470.,  4820., 13720.],\n",
       "       [ 2000.,    40.,   365.,  3201.,  4141., 14141.],\n",
       "       [ 2000.,    50.,   365.,  1851.,  3251., 17701.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lend_pre_smll: | shape: (7, 6) | ndim: 2 | size: 42 | dtype: float64 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [ 2000.,    50.,   365.,  3470.,  4820., 13720.],\n",
       "       [ 2000.,    40.,   365.,  3201.,  4141., 14141.],\n",
       "       [ 2000.,    50.,   365.,  1851.,  3251., 17701.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " stck_4: | shape: (2102, 6) | ndim: 2 | size: 12612 | dtype: float64 \n"
     ]
    }
   ],
   "source": [
    "## Try to vstack or stack to arrays of diff shape\n",
    "lend_num_smll = lend_num[::130,:]\n",
    "display(lend_num_smll)\n",
    "print(show_attr('lend_num_smll'))\n",
    "\n",
    "lend_pre_smll = lend_num[:7,:]\n",
    "display(lend_pre_smll)\n",
    "print(show_attr('lend_pre_smll'))\n",
    "\n",
    "stck_4 = np.vstack((lend_num, lend_num_smll, lend_pre, lend_pre_smll))\n",
    "display(stck_4)\n",
    "print(show_attr('stck_4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365., ...,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365., ...,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365., ...,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [ 2000.,    40.,   365., ...,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365., ...,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365., ...,  4601.,  4601., 16600.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' stck_5: | shape: (1043, 12) | ndim: 2 | size: 12516 | dtype: float64 '"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.hstack() = horizontal stack, a 'wider' array\n",
    "stck_5 = np.hstack((lend_num, lend_pre))\n",
    "display(stck_5)\n",
    "show_attr('stck_5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 2000.  ,  2000.  ],\n",
       "        [   40.  ,    40.  ],\n",
       "        [  365.  ,   365.  ],\n",
       "        [ 3121.  ,  3121.  ],\n",
       "        [ 4241.  ,  4241.  ],\n",
       "        [13621.  , 13621.  ]],\n",
       "\n",
       "       [[ 2000.  ,  2000.  ],\n",
       "        [   40.  ,    40.  ],\n",
       "        [  365.  ,   365.  ],\n",
       "        [ 3061.  ,  3061.  ],\n",
       "        [ 4171.  ,  4171.  ],\n",
       "        [15041.  , 15041.  ]],\n",
       "\n",
       "       [[ 1000.  ,  1000.  ],\n",
       "        [   40.  ,    40.  ],\n",
       "        [  365.  ,   365.  ],\n",
       "        [ 2160.  ,  2160.  ],\n",
       "        [ 3280.  ,  3280.  ],\n",
       "        [15340.  , 15340.  ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 2000.  ,  2250.25],\n",
       "        [   40.  ,    40.  ],\n",
       "        [  365.  ,   365.  ],\n",
       "        [ 4201.  ,  4201.  ],\n",
       "        [ 5001.  ,  5001.  ],\n",
       "        [16600.  , 16600.  ]],\n",
       "\n",
       "       [[ 1000.  ,  1000.  ],\n",
       "        [   40.  ,    40.  ],\n",
       "        [  365.  ,   365.  ],\n",
       "        [ 2080.  ,  2080.  ],\n",
       "        [ 3320.  ,  3320.  ],\n",
       "        [15600.  , 15600.  ]],\n",
       "\n",
       "       [[ 2000.  ,  2000.  ],\n",
       "        [   40.  ,    40.  ],\n",
       "        [  365.  ,   365.  ],\n",
       "        [ 4601.  ,  4601.  ],\n",
       "        [ 4601.  ,  4601.  ],\n",
       "        [16600.  , 16600.  ]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' stck_6: | shape: (1043, 6, 2) | ndim: 3 | size: 12516 | dtype: float64 '"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.dstack() = depth stack. Stacks arrays in the third dimension.\n",
    "# Returns an array of a higher dimension.\n",
    "stck_6 = np.dstack((lend_num, lend_pre))\n",
    "display(stck_6)\n",
    "show_attr('stck_6')     # 1043 matrices of 6 rows and 2 cols each.\n",
    "# 1043 -> Orig_ROWS, 6 -> Orig_COLS -> 2 -> Orig_NDIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,  2000.],\n",
       "       [   40.,    40.],\n",
       "       [  365.,   365.],\n",
       "       [ 3121.,  3121.],\n",
       "       [ 4241.,  4241.],\n",
       "       [13621., 13621.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first array - first index\n",
    "np.dstack((lend_num, lend_pre))[0]\n",
    "# 2 cols of identical vals. Each col contains the 1st row of either lend_num\n",
    "# or len_pre = The first index represents the row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2000., 2000.])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2nd index -> two identical outputs of 2000\n",
    "np.dstack((lend_num, lend_pre))[0,0]\n",
    "# 2nd index refer to the columns of either input array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2000.,    40.,   365.,  3121.,  4241., 13621.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3th index [0,:,0] row[0], all cols, depth[0]\n",
    "np.dstack((lend_num, lend_pre))[0,:,0]\n",
    "# Output is the 1st row of the original dataset 'len_num'\n",
    "# The third index represents which array the values were pulled from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 2000.  ,  2000.  ],\n",
       "        [   40.  ,    40.  ],\n",
       "        [  365.  ,   365.  ],\n",
       "        [ 3121.  ,  3121.  ],\n",
       "        [ 4241.  ,  4241.  ],\n",
       "        [13621.  , 13621.  ]],\n",
       "\n",
       "       [[ 2000.  ,  2000.  ],\n",
       "        [   40.  ,    40.  ],\n",
       "        [  365.  ,   365.  ],\n",
       "        [ 3061.  ,  3061.  ],\n",
       "        [ 4171.  ,  4171.  ],\n",
       "        [15041.  , 15041.  ]],\n",
       "\n",
       "       [[ 1000.  ,  1000.  ],\n",
       "        [   40.  ,    40.  ],\n",
       "        [  365.  ,   365.  ],\n",
       "        [ 2160.  ,  2160.  ],\n",
       "        [ 3280.  ,  3280.  ],\n",
       "        [15340.  , 15340.  ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 2000.  ,  2250.25],\n",
       "        [   40.  ,    40.  ],\n",
       "        [  365.  ,   365.  ],\n",
       "        [ 4201.  ,  4201.  ],\n",
       "        [ 5001.  ,  5001.  ],\n",
       "        [16600.  , 16600.  ]],\n",
       "\n",
       "       [[ 1000.  ,  1000.  ],\n",
       "        [   40.  ,    40.  ],\n",
       "        [  365.  ,   365.  ],\n",
       "        [ 2080.  ,  2080.  ],\n",
       "        [ 3320.  ,  3320.  ],\n",
       "        [15600.  , 15600.  ]],\n",
       "\n",
       "       [[ 2000.  ,  2000.  ],\n",
       "        [   40.  ,    40.  ],\n",
       "        [  365.  ,   365.  ],\n",
       "        [ 4601.  ,  4601.  ],\n",
       "        [ 4601.  ,  4601.  ],\n",
       "        [16600.  , 16600.  ]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' stck_7: | shape: (1043, 6, 2) | ndim: 3 | size: 12516 | dtype: float64 '"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stack w/axis = -1 same a dstack: np.stack() always returns an output that is\n",
    "# exactly 1 dim more tha its inputs ¡?. Since np.dstack() works along the \"third\"\n",
    "# axis, the 2 functions work identically (for 1-D and 2-D arrays)\n",
    "stck_7 = np.stack((lend_num, lend_pre), axis=-1)\n",
    "display(stck_7)\n",
    "show_attr('stck_7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FUTURE_ more on dstack wit tensor rank3 and exambpes from Manual.\n",
    "# and the 5 methods comparative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 methods to replace missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [   nan,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lend_NAN: | shape: (1043, 6) | ndim: 2 | size: 6258 | dtype: float64 \n",
      "Number of NANs: 260\n",
      "64001.0  -  64002.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 2250.25,    46.11,   365.  ,  3895.99,  5160.75, 16571.44])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [64002.,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------ The Final Dataset (array) Preprocessed ------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2000.  ,    40.  ,   365.  ,  3121.  ,  4241.  , 13621.  ],\n",
       "       [ 2000.  ,    40.  ,   365.  ,  3061.  ,  4171.  , 15041.  ],\n",
       "       [ 1000.  ,    40.  ,   365.  ,  2160.  ,  3280.  , 15340.  ],\n",
       "       ...,\n",
       "       [ 2250.25,    40.  ,   365.  ,  4201.  ,  5001.  , 16600.  ],\n",
       "       [ 1000.  ,    40.  ,   365.  ,  2080.  ,  3320.  , 15600.  ],\n",
       "       [ 2000.  ,    40.  ,   365.  ,  4601.  ,  4601.  , 16600.  ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lend_pre: | shape: (1043, 6) | ndim: 2 | size: 6258 | dtype: float64 \n",
      "Number of NANs: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 2250.25,    46.11,   365.  ,  3895.99,  5160.75, 16571.44])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 2250.25,    46.11,   365.  ,  3895.99,  5160.75, 16571.44])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. The way we learn in 8_2 Substituting Missing Values in NDarryas\n",
    "### Probably the third method will be faster and simpler\n",
    "np.set_printoptions(suppress=True)      # to avoid scientific notation when show\n",
    "\n",
    "# 1st read of data (.csv) and calc the original values\n",
    "lend_NAN = np.genfromtxt('Lending-Company-Numeric-Data-NAN.csv', delimiter=';')\n",
    "display(lend_NAN)\n",
    "print(show_attr('lend_NAN'))\n",
    "print('Number of NANs:', np.isnan(lend_NAN).sum())\n",
    "\n",
    "orig_max = np.nanmax(lend_NAN)          \n",
    "orig_max_plus1 = orig_max + 1\n",
    "print(orig_max, ' - ', orig_max_plus1)\n",
    "\n",
    "cols_means = np.nanmean(lend_NAN, axis=0).round(2)\n",
    "display(cols_means)\n",
    "del lend_NAN                            # to free memory cause i'll use other name\n",
    "\n",
    "# 2nd read of data and replace de NANs, at the end by the mean of each column\n",
    "lend_pre1 = np.genfromtxt('Lending-Company-Numeric-Data-NAN.csv',\n",
    "                         delimiter=';',\n",
    "                         filling_values=orig_max_plus1)\n",
    "display(lend_pre1)\n",
    "\n",
    "for i in range(lend_pre1.shape[1]):\n",
    "    lend_pre1[:,i] = np.where(lend_pre1[:,i] == orig_max_plus1,\n",
    "                             cols_means[i],\n",
    "                             lend_pre1[:,i])\n",
    "\n",
    "ln = '-' * 12                           # To show the final resulting array\n",
    "print(f'\\n{ln} The Final Dataset (array) Preprocessed {ln}')\n",
    "display(lend_pre1)\n",
    "print(show_attr('lend_pre'))\n",
    "print('Number of NANs:', np.isnan(lend_pre1).sum())\n",
    "\n",
    "actual_means = np.mean(lend_pre1, axis=0).round(2)\n",
    "display(cols_means, actual_means)\n",
    "np.array_equal(cols_means, actual_means)\n",
    "# NO NANs and the mean of each col doesn't change from original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [   nan,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lend_pre2: | shape: (1043, 6) | ndim: 2 | size: 6258 | dtype: float64 \n",
      "Number of NANs: 260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 2250.25,    46.11,   365.  ,  3895.99,  5160.75, 16571.44])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " NANs_ixs: | shape: (260, 2) | ndim: 2 | size: 520 | dtype: int64 \n",
      "\n",
      "------------ The Final Dataset (array) Preprocessed ------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2000.  ,    40.  ,   365.  ,  3121.  ,  4241.  , 13621.  ],\n",
       "       [ 2000.  ,    40.  ,   365.  ,  3061.  ,  4171.  , 15041.  ],\n",
       "       [ 1000.  ,    40.  ,   365.  ,  2160.  ,  3280.  , 15340.  ],\n",
       "       ...,\n",
       "       [ 2250.25,    40.  ,   365.  ,  4201.  ,  5001.  , 16600.  ],\n",
       "       [ 1000.  ,    40.  ,   365.  ,  2080.  ,  3320.  , 15600.  ],\n",
       "       [ 2000.  ,    40.  ,   365.  ,  4601.  ,  4601.  , 16600.  ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lend_pre: | shape: (1043, 6) | ndim: 2 | size: 6258 | dtype: float64 \n",
      "Number of NANs: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 2250.25,    46.11,   365.  ,  3895.99,  5160.75, 16571.44])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 2250.25,    46.11,   365.  ,  3895.99,  5160.75, 16571.44])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. The way we learn in 8_7 Argument Where in NumPy (using np.argwhere)\n",
    "lend_pre2 = np.genfromtxt('Lending-Company-Numeric-Data-NAN.csv',\n",
    "                          delimiter=';')\n",
    "display(lend_pre2)\n",
    "print(show_attr('lend_pre2'))\n",
    "print('Number of NANs:', np.isnan(lend_pre2).sum())\n",
    "\n",
    "cols_means = np.nanmean(lend_pre2, axis=0).round(2)\n",
    "display(cols_means)\n",
    "\n",
    "# Indices of NANs: 2Darray w/e/row a NAN indice (row,col)\n",
    "NANs_ixs = np.argwhere(np.isnan(lend_pre2))\n",
    "# display(NANs_ixs)     # must have 260 rows, two cols\n",
    "print(show_attr('NANs_ixs'))\n",
    "\n",
    "# Replace NANs in each col with the nammean of such col\n",
    "for Nix in NANs_ixs:         # for e/row of NANs_ixs\n",
    "    # Nix[1]: col of the NAN, same col where i have to search mean\n",
    "    lend_pre2[Nix[0], Nix[1]] = cols_means[Nix[1]]\n",
    "\n",
    "ln = '-' * 12                           # To show the final resulting array\n",
    "print(f'\\n{ln} The Final Dataset (array) Preprocessed {ln}')\n",
    "display(lend_pre2)\n",
    "print(show_attr('lend_pre'))\n",
    "print('Number of NANs:', np.isnan(lend_pre2).sum())\n",
    "\n",
    "actual_means = np.mean(lend_pre2, axis=0).round(2)\n",
    "display(cols_means, actual_means)\n",
    "np.array_equal(cols_means, actual_means)\n",
    "# NO NANs and the mean of each col doesn't change from original\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. tryin nopnzero... FUTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [   nan,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lend_pre4: | shape: (1043, 6) | ndim: 2 | size: 6258 | dtype: float64 \n",
      "Number of NANs: 260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 2250.25,    46.11,   365.  ,  3895.99,  5160.75, 16571.44])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------ The Final Dataset (array) Preprocessed ------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2000.  ,    40.  ,   365.  ,  3121.  ,  4241.  , 13621.  ],\n",
       "       [ 2000.  ,    40.  ,   365.  ,  3061.  ,  4171.  , 15041.  ],\n",
       "       [ 1000.  ,    40.  ,   365.  ,  2160.  ,  3280.  , 15340.  ],\n",
       "       ...,\n",
       "       [ 2250.25,    40.  ,   365.  ,  4201.  ,  5001.  , 16600.  ],\n",
       "       [ 1000.  ,    40.  ,   365.  ,  2080.  ,  3320.  , 15600.  ],\n",
       "       [ 2000.  ,    40.  ,   365.  ,  4601.  ,  4601.  , 16600.  ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lend_pre: | shape: (1043, 6) | ndim: 2 | size: 6258 | dtype: float64 \n",
      "Number of NANs: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 2250.25,    46.11,   365.  ,  3895.99,  5160.75, 16571.44])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 2250.25,    46.11,   365.  ,  3895.99,  5160.75, 16571.44])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. np.where(isnan)\n",
    "lend_pre4 = np.genfromtxt('Lending-Company-Numeric-Data-NAN.csv',\n",
    "                          delimiter=';')\n",
    "display(lend_pre4)\n",
    "print(show_attr('lend_pre4'))\n",
    "print('Number of NANs:', np.isnan(lend_pre4).sum())\n",
    "\n",
    "cols_means = np.nanmean(lend_pre4, axis=0).round(2)\n",
    "display(cols_means)\n",
    "\n",
    "for i in range(lend_pre4.shape[1]):\n",
    "    lend_pre4[:,i] = np.where(np.isnan(lend_pre4[:,i]),\n",
    "                              cols_means[i],\n",
    "                              lend_pre4[:,i])\n",
    "\n",
    "\n",
    "ln = '-' * 12                           # To show the final resulting array\n",
    "print(f'\\n{ln} The Final Dataset (array) Preprocessed {ln}')\n",
    "display(lend_pre4)\n",
    "print(show_attr('lend_pre'))\n",
    "print('Number of NANs:', np.isnan(lend_pre4).sum())\n",
    "\n",
    "actual_means = np.mean(lend_pre4, axis=0).round(2)\n",
    "display(cols_means, actual_means)\n",
    "np.array_equal(cols_means, actual_means)\n",
    "# NO NANs and the mean of each col doesn't change from original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. np.where - np.nan_to_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New from Q&A\n",
    "I think comparing missing values with '==' returns a false boolean\n",
    "Also, I think there is no function called 'ColumnMeans'\n",
    "\n",
    "Alternatively, you can make either of the following\n",
    "\n",
    "1- Pass the value you want to replace in genfromtxt through filling_value parameter, and then use where function to replace your value in specific columns of the dataset\n",
    "\n",
    "2- Simply use 'np.nan_to_num' function\n",
    "so the code should be\n",
    "\n",
    "\n",
    "DataMissing2[:,0] = np.nan_to_num(DataMissing2[:,0], np.nanmean(DataMissing2, axis=0)[0])\n",
    "\n",
    "\n",
    "3- Instead of using 'DataMissing2[:,0] == np.nan== np.nan', use 'isnan' as follow\n",
    "\n",
    "\n",
    "\n",
    "DataMissing2[:,0] = np.where(np.isnan(DataMissing2[:,0]), np.nanmean(DataMissing2, axis=0)[0], DataMissing2[:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2000.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see \n",
    "l_NAN = np.genfromtxt('Lending-Company-Numeric-Data-NAN.csv', delimiter=';')\n",
    "# l_NAN\n",
    "Ncoords = np.argwhere(np.isnan(l_NAN))\n",
    "print(l_NAN[Ncoords[0,0],Ncoords[0,1] ])\n",
    "print(l_NAN[Ncoords[9,0],Ncoords[9,1] ])\n",
    "\n",
    "type(np.nan)    # <class 'float'>\n",
    "print(l_NAN[Ncoords[0,0],Ncoords[0,1]] == np.nan)   # False\n",
    "print(np.isnan(l_NAN[Ncoords[0,0],Ncoords[0,1]]))   # True\n",
    "np.nan_to_num(l_NAN[Ncoords[0,0],Ncoords[0,1]])     # 0.0\n",
    "\n",
    "print(np.nan_to_num(l_NAN[Ncoords[0,0],Ncoords[0,1]]) == 0)     # True\n",
    "print(np.nan_to_num(l_NAN[Ncoords[0,0],Ncoords[0,1]]) == 0.0)   # True\n",
    "print(np.nan_to_num(l_NAN[0,0]) == 0)   # False\n",
    "np.nan_to_num(l_NAN[0,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
