{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Data Preprocessing with NumPy\n",
    "## 9. A Loan Data Practical Example with NumPy\n",
    "- Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[### 0. Import Libraries, set_printoptions, and def funct](#0-import-libraries-set_printoptions-and-def-funct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Import Libraries, set_printoptions, and def funct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.__version__\n",
    "np.set_printoptions(suppress=True, linewidth=100, precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function show_attr\n",
    "\n",
    "def show_attr(arrnm: str) -> str:\n",
    "    strout = f' {arrnm}: '\n",
    "\n",
    "    for attr in ('shape', 'ndim', 'size', 'dtype'):     #, 'itemsize'):\n",
    "            arrnm_attr = arrnm + '.' + attr\n",
    "            strout += f'| {attr}: {eval(arrnm_attr)} '\n",
    "\n",
    "    return strout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setting Up: Introduction to the Practical Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What working as a data analyst in a data science team looks like\n",
    "1. Introduce the project.\n",
    "2. All the Tasks and Responsibilities that the head of data analytics assigned to us.\n",
    "3. Examine the dataset (before we start cleaning and prepro)\n",
    "4. Cleaning and Preprocessing the dataset.\n",
    "5. Save it to an external *.csv file (once the data is ready to be analyzed).\n",
    "6. Pass it on to the data scientists.\n",
    "> DScientist: will use the cleaning and prepro dtset to construct a CRM (credit risk model), that measures probability of default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structure of the working process\n",
    "- Gathering (Recopilación de información), Cleaning and Preprocessing the Data <- Data Analysts\n",
    "- DAnalysts hand them over to the DScientists (ML knowlegde) to construct complex Predictive Models.\n",
    "##### DAnalysts Rol:\n",
    "1. Our goal is to obtain a clean and preprocessed dataset\n",
    "2. We'll note down all the changes we're making to the original dataset in a documentation file where we describe what each column of the new dtset represents.\n",
    "3. This info will be invaluable to the DScientists who will work with this data after us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A day in the life of a DAnalyst\n",
    "- Explain our role in the project.\n",
    "- Examine the data.\n",
    "- Import the data.\n",
    "- Split the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Case\n",
    "- Rol: DAnalyst in a data science team of central bank in Europe.\n",
    "- Team assignment: create a CRM which estimates the probability of default for every personal account.\n",
    "- Terms like Probability of default, Recovery rate, and Credit Risk Modeling.\n",
    "- Chore: Take the raw dataset and prepare it for the models the plan to run.\n",
    "- Details provided:\n",
    "    1. What data is stored in every column.\n",
    "    2. Set of rules on how to clean and pre-process the values in each column col.\n",
    "> The essence of the DAnalyst job and is much more demanding and sizable than it might initially sound."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step by Step approach to the problem\n",
    "1. Loan data is a sample from a larger dtset that belongs to an affiliate bank based in USA. Therefore all the values are in dollars, so we need to provide their Euro equivalents.\n",
    "2. Every categorical variable must be quantified. We nee to change any text columns into numbers based on the info they contain.\n",
    "    - Issue date (fecha de emisión) on each loan: transformation is straightforward since we can split the accounts by months.\n",
    "    - For other cols, we only care if they provide positive or negative connotations. So we'll be turning them into __*dummy variables*__ that hold either zero or one.\n",
    "3. Missing Data:\n",
    "    - Furthermore when we're measuring creditworthiness we need to be extremely risk-averse and distrustful of any unavailable data.\n",
    "    - That's why the consensus in the field is that missing info suggest foul play because loan applications are self reported. To elaborate since candidates fill out their loan applications manually, there is an incentive to withhold info which can lower their chances of getting a loan.\n",
    "    - Of course we prefer to give out loans to applicants who can repay them. So __*if the information isn´t available, we'll just assume the worst*__.\n",
    "    - What is worst varies from one column to the next, so the team has provided us with casting directions for each variable in the dtset.\n",
    "    - Therefore as we go through the dtset we'll usually know whether we want to use the minimum, maximum, or some other value when taking care of missing data\n",
    "\n",
    "> Loan info is store in a .csv file called loan-data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Setting Up: Importing the Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,         nan,    35000.  , ...,         nan,         nan,     9452.96],\n",
       "       [57693261.  ,         nan,    30000.  , ...,         nan,         nan,     4679.7 ],\n",
       "       [59432726.  ,         nan,    15000.  , ...,         nan,         nan,     1969.83],\n",
       "       ...,\n",
       "       [50415990.  ,         nan,    10000.  , ...,         nan,         nan,     2185.64],\n",
       "       [46154151.  ,         nan,         nan, ...,         nan,         nan,     3199.4 ],\n",
       "       [66055249.  ,         nan,    10000.  , ...,         nan,         nan,      301.9 ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' raw_data_np: | shape: (10000, 14) | ndim: 2 | size: 140000 | dtype: float64 '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_data_np = np.genfromtxt('9_loan-data.csv',\n",
    "                            delimiter=';',\n",
    "                            skip_header=1,\n",
    "                            autostrip=True)\n",
    "display(raw_data_np)\n",
    "display(show_attr('raw_data_np'))\n",
    "\n",
    "# The entire 1st row is NAN so the skip_header=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Setting Up: Checking for Incomplete Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NANs:  88005\n",
      "Original Maximum:  68616519.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "68616520.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmonti\\AppData\\Local\\Temp\\ipykernel_5612\\1101693491.py:6: RuntimeWarning: Mean of empty slice\n",
      "  display(orig_means := np.nanmean(raw_data_np, axis=0))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([54015809.19,         nan,    15273.46,         nan,    15311.04,         nan,       16.62,\n",
       "            440.92,         nan,         nan,         nan,         nan,         nan,     3143.85])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmonti\\AppData\\Local\\Temp\\ipykernel_5612\\1101693491.py:8: RuntimeWarning: All-NaN slice encountered\n",
      "  orig_stats = np.array([np.nanmin(raw_data_np, axis=0),\n",
      "C:\\Users\\jmonti\\AppData\\Local\\Temp\\ipykernel_5612\\1101693491.py:10: RuntimeWarning: All-NaN slice encountered\n",
      "  np.nanmax(raw_data_np, axis=0)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  373332.  ,         nan,     1000.  ,         nan,     1000.  ,         nan,        6.  ,\n",
       "              31.42,         nan,         nan,         nan,         nan,         nan,        0.  ],\n",
       "       [54015809.19,         nan,    15273.46,         nan,    15311.04,         nan,       16.62,\n",
       "             440.92,         nan,         nan,         nan,         nan,         nan,     3143.85],\n",
       "       [68616519.  ,         nan,    35000.  ,         nan,    35000.  ,         nan,       28.99,\n",
       "            1372.97,         nan,         nan,         nan,         nan,         nan,    41913.62]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Number of NANs: ', np.isnan(raw_data_np).sum())\n",
    "\n",
    "# Calc tmp_fill and orig_mean for e/col, then orig_stats e/col\n",
    "print('Original Maximum: ', np.nanmax(raw_data_np))\n",
    "display(tmp_fill := np.nanmax(raw_data_np) + 1)\n",
    "display(orig_means := np.nanmean(raw_data_np, axis=0))\n",
    "\n",
    "orig_stats = np.array([np.nanmin(raw_data_np, axis=0),\n",
    "                       orig_means,\n",
    "                       np.nanmax(raw_data_np, axis=0)])\n",
    "display(orig_stats)\n",
    "\n",
    "# orig_means =>  can see 8 cols full of NAN (warnings) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Setting Up: Splitting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  3,  5,  8,  9, 10, 11, 12], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  4,  6,  7, 13], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the cols_str(ixs), and the cols_num(ixs)\n",
    "cols_str = np.argwhere(np.isnan(orig_means)).squeeze()\n",
    "display(cols_str)\n",
    "\n",
    "# cols_num = np.argwhere(~np.isnan(orig_means)).squeeze()\n",
    "cols_num = np.argwhere(np.isnan(orig_means) == False).squeeze()\n",
    "display(cols_num)\n",
    "\n",
    "# Check: num_cols_str + num_cols_num = raw_data.shape[1]\n",
    "len(cols_str) + len(cols_num) == raw_data_np.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['May-15', 'Current', '36 months', ..., 'Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=48010226', 'CA'],\n",
       "       ['', 'Current', '36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=57693261', 'NY'],\n",
       "       ['Sep-15', 'Current', '36 months', ..., 'Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=59432726', 'PA'],\n",
       "       ...,\n",
       "       ['Jun-15', 'Current', '36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=50415990', 'CA'],\n",
       "       ['Apr-15', 'Current', '36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=46154151', 'OH'],\n",
       "       ['Dec-15', 'Current', '36 months', ..., '',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=66055249', 'IL']],\n",
       "      dtype='<U69')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' data_str: | shape: (10000, 8) | ndim: 2 | size: 80000 | dtype: <U69 '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reload strings cols to build the str sub-array (now data)\n",
    "data_str = np.genfromtxt('9_loan-data.csv',\n",
    "                         delimiter=';',\n",
    "                         dtype=str,\n",
    "                         usecols=cols_str,\n",
    "                         skip_header=1,\n",
    "                         autostrip=True)\n",
    "display(data_str)\n",
    "show_attr('data_str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    35000.  ,       13.33,     1184.86,     9452.96],\n",
       "       [57693261.  ,    30000.  ,    30000.  , 68616520.  ,      938.57,     4679.7 ],\n",
       "       [59432726.  ,    15000.  ,    15000.  , 68616520.  ,      494.86,     1969.83],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,    10000.  , 68616520.  , 68616520.  ,     2185.64],\n",
       "       [46154151.  , 68616520.  ,    10000.  ,       16.55,      354.3 ,     3199.4 ],\n",
       "       [66055249.  ,    10000.  ,    10000.  , 68616520.  ,      309.97,      301.9 ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' data_num: | shape: (10000, 6) | ndim: 2 | size: 60000 | dtype: float64 '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of NANs: 0\n"
     ]
    }
   ],
   "source": [
    "# Reload numeric cols to build the num sub-array (now data)\n",
    "# ALSO fill NANs w/temp_fill\n",
    "data_num = np.genfromtxt('9_loan-data.csv',\n",
    "                         delimiter=';',\n",
    "                         usecols=cols_num,\n",
    "                         skip_header=1,\n",
    "                         autostrip=True,\n",
    "                         filling_values=tmp_fill)\n",
    "display(data_num)\n",
    "display(show_attr('data_num'))\n",
    "print(\"Num of NANs:\", np.isnan(data_num).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_d', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' header_str: | shape: (8,) | ndim: 1 | size: 8 | dtype: <U19 '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load header strings cols to build the str sub-array (now header)\n",
    "header_str = np.genfromtxt('9_loan-data.csv',\n",
    "                            delimiter=';',\n",
    "                            dtype=str,\n",
    "                            usecols=cols_str,\n",
    "                            skip_footer=raw_data_np.shape[0],\n",
    "                            autostrip=True)\n",
    "display(header_str)\n",
    "show_attr('header_str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt'], dtype='<U11')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' header_num: | shape: (6,) | ndim: 1 | size: 6 | dtype: <U11 '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load header numeric cols to build the num sub-array (now header)\n",
    "header_num = np.genfromtxt('9_loan-data.csv',\n",
    "                            delimiter=';',\n",
    "                            dtype=str,\n",
    "                            usecols=cols_num,\n",
    "                            skip_footer=raw_data_np.shape[0],\n",
    "                            autostrip=True)\n",
    "display(header_num)\n",
    "show_attr('header_num')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Setting Up: Creating Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function chkpt (checkpoint)\n",
    "\n",
    "def chkpt(filenm: str, chk_header: np.ndarray,\n",
    "          chk_data: np.ndarray) -> np.lib.npyio.NpzFile:\n",
    "    np.savez(filenm, header=chk_header, data=chk_data)\n",
    "    chkpt_var = np.load(f'{filenm}.npz')\n",
    "    return chkpt_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['header', 'data']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chkpt_tst = chkpt('chkpt-tst', header_num, data_num)\n",
    "display(chkpt_tst.files)\n",
    "np.array_equal(chkpt_tst['data'], data_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Manipulating Text Data: Issue Date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Chg header of col issue_d to issue_date (more descriptive)\n",
    "- Eliminate -15 (all 2015) and change month str by num (1-12) [0-for '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_d', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"header_str[0] = 'issue_date'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Chg header of col issue_d to issue_date (more descriptive)\n",
    "display(header_str)\n",
    "display(np.argwhere(header_str == 'issue_d'))\n",
    "header_str[0] = 'issue_date'\n",
    "display(f'{header_str[0] = }')\n",
    "display(header_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'Apr-15', 'Aug-15', 'Dec-15', 'Feb-15', 'Jan-15', 'Jul-15', 'Jun-15', 'Mar-15',\n",
       "       'May-15', 'Nov-15', 'Oct-15', 'Sep-15'], dtype='<U69')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 500,  757,  846,  997,  530,  770, 1061,  654,  559,  741,  847, 1095,  643], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array(['', 'Feb-15', 'Mar-15', 'Sep-15', 'Jun-15', 'May-15', 'Apr-15', 'Jan-15', 'Aug-15',\n",
       "        'Nov-15', 'Dec-15', 'Jul-15', 'Oct-15'], dtype='<U69'),\n",
       " array([ 500,  530,  559,  643,  654,  741,  757,  770,  846,  847,  997, 1061, 1095], dtype=int64))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the column AND jm- view sort in order of counts\n",
    "id_uniq, id_ucnt = np.unique(data_str[:,0], return_counts=True)\n",
    "display(id_uniq, id_ucnt)\n",
    "id_ucnt_ixsorted = np.argsort(id_ucnt)\n",
    "id_uniq[id_ucnt_ixsorted], id_ucnt[id_ucnt_ixsorted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'Apr', 'Aug', 'Dec', 'Feb', 'Jan', 'Jul', 'Jun', 'Mar', 'May', 'Nov', 'Oct', 'Sep'],\n",
       "      dtype='<U69')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '10', '11', '12', '2', '3', '4', '5', '6', '7', '8', '9'], dtype='<U69')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['0', '12', '5', '9', '4', '6', '1', '2', '10', '7', '11', '3', '8'], dtype='<U69')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Eliminate -15 \n",
    "data_str[:,0] = np.chararray.strip(data_str[:,0], '-15')\n",
    "display(np.unique(data_str[:,0]))\n",
    "\n",
    "# Replace month str by number - '' = 0\n",
    "months = np.array(['', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "                   'Jul', 'Aug', 'Sep', 'Oct', 'Nov','Dec'])\n",
    "\n",
    "for mth_num in range(13):\n",
    "    data_str[:,0] = np.where(data_str[:,0] == months[mth_num],\n",
    "                             mth_num,\n",
    "                             data_str[:,0])\n",
    "    \n",
    "display(np.unique(data_str[:,0]))\n",
    "display(np.unique(data_str[:,0])[id_ucnt_ixsorted])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Manipulating Text Data: Loan Status and Term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 'loan_status' -> dummy variable 0 or 1\n",
    "- 'term' -> only numeric and change name to 'term_month'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[1]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['', 'Charged Off', 'Current', 'Default', 'Fully Paid', 'In Grace Period', 'Issued',\n",
       "       'Late (16-30 days)', 'Late (31-120 days)'], dtype='<U69')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['0', '1'], dtype='<U69')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 'loan_status' -> dummy var with 'loan_satus' values\n",
    "display(header_str)\n",
    "display(np.argwhere(header_str == 'loan_status'))\n",
    "display(np.unique(data_str[:,1]))\n",
    "\n",
    "bad = np.array(['', 'Charged Off', 'Default', 'Late (31-120 days)'])\n",
    "# good = ['Current', 'Fully Paid', 'In Grace Period', 'Issued', 'Late (16-30 days)']\n",
    "data_str[:,1] = np.where(np.isin(data_str[:,1], bad), 0, 1)\n",
    "\n",
    "display(np.unique(data_str[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[2]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['', '36 months', '60 months'], dtype='<U69')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['', '36', '60'], dtype='<U69')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['36', '60'], dtype='<U69')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'term'\n",
    "display(header_str)\n",
    "display(np.argwhere(header_str == 'term'))\n",
    "display(np.unique(data_str[:,2]))\n",
    "\n",
    "# Eliminate letters\n",
    "data_str[:,2] = np.chararray.strip(data_str[:,2], ' months')\n",
    "display(np.unique(data_str[:,2]))\n",
    "\n",
    "# replace '' by 60 (worst case)\n",
    "data_str[:,2] = np.where(data_str[:,2] == '',\n",
    "                         '60',\n",
    "                         data_str[:,2])\n",
    "\n",
    "np.unique(data_str[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change header_str 'term' by 'term_month'\n",
    "header_str[2] = 'term_month'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Manipulating Text Data: Grade and Sub Grade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 'sub_grade' includes grade. But use Grade to fill the empties sub_grades with the worst case (5). Remaining sub_grade empties fill with new worst category (H1)\n",
    "- Remove grade from data and header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_month', 'grade', 'sub_grade', 'verification_status',\n",
       "       'url', 'addr_state'], dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[3]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['', 'A', 'B', 'C', 'D', 'E', 'F', 'G'], dtype='<U69')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[4]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array(['', 'A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C1', 'C2', 'C3', 'C4',\n",
       "        'C5', 'D1', 'D2', 'D3', 'D4', 'D5', 'E1', 'E2', 'E3', 'E4', 'E5', 'F1', 'F2', 'F3', 'F4',\n",
       "        'F5', 'G1', 'G2', 'G3', 'G4', 'G5'], dtype='<U69'),\n",
       " array([514, 285, 278, 239, 323, 502, 509, 517, 530, 553, 494, 629, 567, 586, 564, 423, 391, 267,\n",
       "        250, 255, 223, 235, 162, 171, 139, 114,  94,  52,  34,  43,  16,  19,  10,   3,   7,   2],\n",
       "       dtype=int64))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let´s see grade and sub_grade columns\n",
    "display(header_str)\n",
    "display(np.argwhere(header_str == 'grade'))\n",
    "display(np.unique(data_str[:,3]))\n",
    "\n",
    "display(np.argwhere(header_str == 'sub_grade'))\n",
    "display(np.unique(data_str[:,4], return_counts=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['', 'A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C1', 'C2', 'C3', 'C4',\n",
       "        'C5', 'D1', 'D2', 'D3', 'D4', 'D5', 'E1', 'E2', 'E3', 'E4', 'E5', 'F1', 'F2', 'F3', 'F4',\n",
       "        'F5', 'G1', 'G2', 'G3', 'G4', 'G5'], dtype='<U69'),\n",
       " array([  9, 285, 278, 239, 323, 592, 509, 517, 530, 553, 633, 629, 567, 586, 564, 577, 391, 267,\n",
       "        250, 255, 288, 235, 162, 171, 139, 160,  94,  52,  34,  43,  24,  19,  10,   3,   7,   5],\n",
       "       dtype=int64))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Replace de empties subgrades w/corresponding grade + 5 (worst case)\n",
    "for gd in np.unique(data_str[:,3])[1:]:\n",
    "    data_str[:,4] = np.where((data_str[:,4] == '') & (data_str[:,3] == gd),\n",
    "                             gd + '5',\n",
    "                             data_str[:,4])\n",
    "    \n",
    "display(np.unique(data_str[:,4], return_counts=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C1', 'C2', 'C3', 'C4', 'C5',\n",
       "        'D1', 'D2', 'D3', 'D4', 'D5', 'E1', 'E2', 'E3', 'E4', 'E5', 'F1', 'F2', 'F3', 'F4', 'F5',\n",
       "        'G1', 'G2', 'G3', 'G4', 'G5', 'H1'], dtype='<U69'),\n",
       " array([285, 278, 239, 323, 592, 509, 517, 530, 553, 633, 629, 567, 586, 564, 577, 391, 267, 250,\n",
       "        255, 288, 235, 162, 171, 139, 160,  94,  52,  34,  43,  24,  19,  10,   3,   7,   5,   9],\n",
       "       dtype=int64))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Replace the remaining sub_grade '' w/ H1\n",
    "data_str[:,4] = np.where(data_str[:,4] == '', 'H1', data_str[:,4])\n",
    "display(np.unique(data_str[:,4], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_month', 'sub_grade', 'verification_status', 'url',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove grade col from header\n",
    "header_str = np.delete(header_str, 3)\n",
    "display(header_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C1', 'C2', 'C3', 'C4', 'C5',\n",
       "       'D1', 'D2', 'D3', 'D4', 'D5', 'E1', 'E2', 'E3', 'E4', 'E5', 'F1', 'F2', 'F3', 'F4', 'F5',\n",
       "       'G1', 'G2', 'G3', 'G4', 'G5', 'H1'], dtype='<U69')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove grade from data\n",
    "data_str = np.delete(data_str, 3, axis=1)\n",
    "np.unique(data_str[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22',\n",
       "       '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36',\n",
       "       '4', '5', '6', '7', '8', '9'], dtype='<U69')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert all the sub_grades to num (A1-1 and H1...)\n",
    "display(sze := np.unique(data_str[:,3]).size)   # or .shap[0]\n",
    "dic_sub_gd= dict(zip(np.unique(data_str[:,3]), range(1, sze + 1)))\n",
    "# print(dic)\n",
    "\n",
    "for k in np.unique(data_str[:,3]):\n",
    "    data_str[:,3] = np.where(data_str[:,3] == k,\n",
    "                             dic_sub_gd[k],\n",
    "                             data_str[:,3])\n",
    "    \n",
    "\n",
    "np.unique(data_str[:,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Manipulating Text Data: Verification Status & URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 'verification_status' -> dummy (0-1)\n",
    "- 'url' -> check that's not necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_month', 'sub_grade', 'verification_status', 'url',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array(['', 'Not Verified', 'Source Verified', 'Verified'], dtype='<U69'),\n",
       " array([ 500, 2673, 4116, 2711], dtype=int64))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array(['https://www.lendingclub.com/browse/loanDetail.action?loan_id=12606806',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=13026045',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=1312426', ...,\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=8138291',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=8214572',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=849994'], dtype='<U69'),\n",
       " array([1, 1, 1, ..., 1, 1, 1], dtype=int64))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's see them\n",
    "display(header_str)\n",
    "display(np.unique(data_str[:,4], return_counts=True))\n",
    "display(np.unique(data_str[:,5], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['0', '1'], dtype='<U69'), array([3173, 6827], dtype=int64))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make verification_status as dummy (0-bad)\n",
    "bad = np.array(['', 'Not Verified'])\n",
    "# good = ('Source Verified', 'Verified')\n",
    "data_str[:,4] = np.where(np.isin(data_str[:,4], bad), 0, 1)\n",
    "display(np.unique(data_str[:,4], return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Manipulating Text Data: State Address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 'addr_state': One state missing and lot of ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_month', 'sub_grade', 'verification_status', 'url',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array(['', 'AK', 'AL', 'AR', 'AZ', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA', 'HI', 'IL', 'IN',\n",
       "        'KS', 'KY', 'LA', 'MA', 'MD', 'ME', 'MI', 'MN', 'MO', 'MS', 'MT', 'NC', 'ND', 'NE', 'NH',\n",
       "        'NJ', 'NM', 'NV', 'NY', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VA',\n",
       "        'VT', 'WA', 'WI', 'WV', 'WY'], dtype='<U69'),\n",
       " array([ 500,   26,  119,   74,  220, 1336,  201,  143,   27,   27,  690,  321,   44,  389,  152,\n",
       "          84,   84,  116,  210,  222,   10,  267,  156,  160,   61,   28,  261,   16,   25,   58,\n",
       "         341,   57,  130,  777,  312,   83,  108,  320,   40,  107,   24,  143,  758,   74,  242,\n",
       "          17,  216,  148,   49,   27], dtype=int64))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([-1336,  -777,  -758,  -690,  -500,  -389,  -341,  -321,  -320,  -312,  -267,  -261,  -242,\n",
       "        -222,  -220,  -216,  -210,  -201,  -160,  -156,  -152,  -148,  -143,  -143,  -130,  -119,\n",
       "        -116,  -108,  -107,   -84,   -84,   -83,   -74,   -74,   -61,   -58,   -57,   -49,   -44,\n",
       "         -40,   -28,   -27,   -27,   -27,   -26,   -25,   -24,   -17,   -16,   -10], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Display status\n",
    "display(header_str)\n",
    "uniq_states = np.unique(data_str[:,6], return_counts=True)\n",
    "display(uniq_states)\n",
    "np.sort(-uniq_states[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CA', 'NY', 'TX', 'FL', '', 'IL', 'NJ', 'GA', 'PA', 'OH', 'MI', 'NC', 'VA', 'MD', 'AZ',\n",
       "       'WA', 'MA', 'CO', 'MO', 'MN', 'IN', 'WI', 'CT', 'TN', 'NV', 'AL', 'LA', 'OR', 'SC', 'KY',\n",
       "       'KS', 'OK', 'UT', 'AR', 'MS', 'NH', 'NM', 'WV', 'HI', 'RI', 'MT', 'DE', 'DC', 'WY', 'AK',\n",
       "       'NE', 'SD', 'VT', 'ND', 'ME'], dtype='<U69')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([1336,  777,  758,  690,  500,  389,  341,  321,  320,  312,  267,  261,  242,  222,  220,\n",
       "        216,  210,  201,  160,  156,  152,  148,  143,  143,  130,  119,  116,  108,  107,   84,\n",
       "         84,   83,   74,   74,   61,   58,   57,   49,   44,   40,   28,   27,   27,   27,   26,\n",
       "         25,   24,   17,   16,   10], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. Sort in descending order the states - np.argsort()\n",
    "ixs = np.argsort(-uniq_states[1])\n",
    "display(uniq_states[0][ixs])\n",
    "display(uniq_states[1][ixs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], dtype='<U69')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Assign '' = 0, to no enter any category\n",
    "data_str[:,6][data_str[:,6] == ''] = '0'\n",
    "\n",
    "data_str[:,6][data_str[:,6] == '0']\n",
    "# data_str[:,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Manipulating Text Data: Converting Strings and Creating a Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Manipulating Numeric Data: Substitute Filler Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
