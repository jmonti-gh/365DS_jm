{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. A Loan Data Practical Example with NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1. Setting Up: Importing the Data Set](#01)    \n",
    "[2. Setting Up: Checking for Incomplete Data](#02)    \n",
    "[6. Manipulating Text Data: Loan Status and Term](#06)    \n",
    "[7. Manipulating Text Data: Grade and Sub Grade](#07)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[8. Manipulating Text Data: Verification Status & URL](#08)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[9. Manipulating Text Data: State Address](#09)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[10. Manipulating Text Data: Converting Strings and Creating a Checkpoint](#10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[## 11. Manipulating Numeric Data: Substitute Filler Values](#11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[JM Walrus Operator Discover](#JM-Walrus-Operator-Discover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting Up: Introduction to the Practical Example\n",
    "Setting Up: Importing the Data Set\n",
    "Setting Up: Checking for Incomplete Data\n",
    "Setting Up: Splitting the Dataset\n",
    "Setting Up: Creating Checkpoints\n",
    "Manipulating Text Data: Issue Date\n",
    "Manipulating Text Data: Loan Status and Term\n",
    "Manipulating Text Data: Grade and Sub Grade\n",
    "Manipulating Text Data: Verification Status & URL\n",
    "Manipulating Text Data: State Address\n",
    "Manipulating Text Data: Converting Strings and Creating a Checkpoint\n",
    "Manipulating Numeric Data: Substitute Filler Values\n",
    "Manipulating Numeric Data: Currency Change - The Exchange Rate\n",
    "Manipulating Numeric Data: Currency Change - From USD to EUR|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Importing Libraries and Defining Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NumPy library, show version, set_printoptions to better see the data\n",
    "- def show_attr(arrnm): to view arrays attributes: shape, ndim, size, dtype.\n",
    "- def chkpt(filenm, chk_header, chk_data): to create Checkpoints for the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.__version__\n",
    "np.set_printoptions(suppress=True, linewidth=100, precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function show_attr\n",
    "\n",
    "def show_attr(arrnm: str) -> str:\n",
    "    strout = f' {arrnm}: '\n",
    "\n",
    "    for attr in ('shape', 'ndim', 'size', 'dtype'):     #, 'itemsize'):\n",
    "            arrnm_attr = arrnm + '.' + attr\n",
    "            strout += f'| {attr}: {eval(arrnm_attr)} '\n",
    "\n",
    "    return strout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function show_thseps\n",
    "\n",
    "def show_thseps(num: float, underscore: bool = False) -> str:\n",
    "    '''Insert thousand separators'''\n",
    "    \n",
    "    sep = ','\n",
    "    if underscore:\n",
    "        sep = '_'\n",
    "\n",
    "    n_str = str(num)\n",
    "    dec_ix = n_str.find('.')\n",
    "    if dec_ix > -1:\n",
    "        dec_part = n_str[dec_ix:]\n",
    "    else:\n",
    "        dec_part = ''\n",
    "\n",
    "    int_pr = n_str[:dec_ix][::-1]\n",
    "    int_part = ''\n",
    "    for i in range(len(int_pr)):\n",
    "        int_part += int_pr[i]\n",
    "        if (i + 1) % 3 == 0:\n",
    "            int_part += sep\n",
    "    \n",
    "    return int_part[::-1] + dec_part    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function chkpt (checkpoint)\n",
    "\n",
    "def chkpt(filenm: str, chk_header: np.ndarray,\n",
    "          chk_data: np.ndarray) -> np.lib.npyio.NpzFile:\n",
    "    np.savez(filenm, header=chk_header, data=chk_data)\n",
    "    chkpt_var = np.load(f'{filenm}.npz')\n",
    "    return chkpt_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"01\"></a>\n",
    "## 1. Setting Up: Importing the Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick glance at loan-data.csv (notepad++)\n",
    "- Contains both text and numeric data.\n",
    "- A header clarifying the contents of each column\n",
    "- 1st col is called 'id' -> each row consists of info for the account of a loan candidate's application and each candidate is described by their id. => We referred to the rows as accounts, candidates or applications.\n",
    "- Can't see whether there are missing values in the dtset.\n",
    "- ';' as delimiter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### genfromtxt(autostrip=False)\n",
    "- autostrip: bool, optional\n",
    "Whether to automatically strip white spaces from the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,         nan,    35000.  , ...,         nan,         nan,     9452.96],\n",
       "       [57693261.  ,         nan,    30000.  , ...,         nan,         nan,     4679.7 ],\n",
       "       [59432726.  ,         nan,    15000.  , ...,         nan,         nan,     1969.83],\n",
       "       ...,\n",
       "       [50415990.  ,         nan,    10000.  , ...,         nan,         nan,     2185.64],\n",
       "       [46154151.  ,         nan,         nan, ...,         nan,         nan,     3199.4 ],\n",
       "       [66055249.  ,         nan,    10000.  , ...,         nan,         nan,      301.9 ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' raw_data_np: | shape: (10000, 14) | ndim: 2 | size: 140000 | dtype: float64 '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of NANs: 88005\n"
     ]
    }
   ],
   "source": [
    "raw_data_np = np.genfromtxt('9_loan-data.csv',\n",
    "                            delimiter=';',\n",
    "                            skip_header=1,\n",
    "                            autostrip=True)\n",
    "display(raw_data_np)\n",
    "display(show_attr('raw_data_np'))\n",
    "print('Num of NANs:', np.isnan(raw_data_np).sum())\n",
    "\n",
    "# Lot of NANs, either text or missing\n",
    "# The entire 1st row is NAN so the skip_header=1\n",
    "# autostrip cause it removes white spaces which can distort our cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"02\"></a>\n",
    "## 2. Setting Up: Checking for Incomplete Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I calc NANs num early: 88_005\n",
    "- Also calc and store temp_fill, orig_means, and orig_stats[mins, means, maxs] <- over Cols>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jm\\AppData\\Local\\Temp\\ipykernel_9752\\4186509109.py:5: RuntimeWarning: Mean of empty slice\n",
      "  orig_means = np.nanmean(raw_data_np, axis=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "68616520.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([54015809.19,         nan,    15273.46,         nan,    15311.04,         nan,       16.62,\n",
       "            440.92,         nan,         nan,         nan,         nan,         nan,     3143.85])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan, nan, nan, nan])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have 88_005 NANs to take care\n",
    "# 1st calc the orig_means of e/col to have an idea\n",
    "\n",
    "temp_fill = np.nanmax(raw_data_np) + 1          # *Note*\n",
    "orig_means = np.nanmean(raw_data_np, axis=0)\n",
    "display(temp_fill, orig_means)\n",
    "# .py:3: RuntimeWarning: Mean of empty slice\n",
    "# 8 cols [1,3,5,8-12] full of NAN (empty or strings)\n",
    "\n",
    "display(orig_means[[1,3,5,8,9,10,11,12]])\n",
    "np.isnan(orig_means).sum()\n",
    "\n",
    "# *Note*: it not necessary, there are faster 'Replacement NANs' methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data in next steps.\n",
    "- NumPy doesn't like when we store multiple type of data like numbers and text in the same array.\n",
    "- Since it limits what we can do with the dtset.\n",
    "- We should split the data into two smaller arrays:\n",
    "    1. One containing the numeric values\n",
    "    2. and another one the strings\n",
    "> Before we do so we should extract the minimum and maximum values for each numeric columm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jm\\AppData\\Local\\Temp\\ipykernel_9752\\2288172437.py:2: RuntimeWarning: All-NaN slice encountered\n",
      "  orig_stats = np.array([np.nanmin(raw_data_np, axis=0),\n",
      "C:\\Users\\jm\\AppData\\Local\\Temp\\ipykernel_9752\\2288172437.py:4: RuntimeWarning: All-NaN slice encountered\n",
      "  np.nanmax(raw_data_np, axis=0)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  373332.  ,         nan,     1000.  ,         nan,     1000.  ,         nan,        6.  ,\n",
       "              31.42,         nan,         nan,         nan,         nan,         nan,        0.  ],\n",
       "       [54015809.19,         nan,    15273.46,         nan,    15311.04,         nan,       16.62,\n",
       "             440.92,         nan,         nan,         nan,         nan,         nan,     3143.85],\n",
       "       [68616519.  ,         nan,    35000.  ,         nan,    35000.  ,         nan,       28.99,\n",
       "            1372.97,         nan,         nan,         nan,         nan,         nan,    41913.62]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before split (num / strings) calc min and max for each col and store \n",
    "orig_stats = np.array([np.nanmin(raw_data_np, axis=0),\n",
    "                      orig_means,\n",
    "                      np.nanmax(raw_data_np, axis=0)])\n",
    "orig_stats\n",
    "# Of course two warnings for the entire NANs in calcs of min and max\n",
    "# We'll use later to fill missing with the worst case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Splitting the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- An data_str and data num. Reload separated arrays. Check NANs\n",
    "- Also fill NANs in data num. Also load header_str and header_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  3,  5,  8,  9, 10, 11, 12], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  4,  6,  7, 13], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the cols_str(ixs), and the cols_num(ixs)\n",
    "# cols_str = np.argwhere(np.isnan(orig_means)).reshape(8,)\n",
    "cols_str = np.argwhere(np.isnan(orig_means)).squeeze()\n",
    "display(cols_str)\n",
    "\n",
    "# cols_num = np.argwhere(~np.isnan(orig_means)).squeeze()\n",
    "cols_num = np.argwhere(np.isnan(orig_means) == False).squeeze()\n",
    "display(cols_num)\n",
    "\n",
    "# Check: num_cols_str + num_cols_num = raw_data.shape[1]\n",
    "len(cols_str) + len(cols_num) == raw_data_np.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['May-15', 'Current', ' 36 months', ..., 'Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=48010226', 'CA'],\n",
       "       ['', 'Current', ' 36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=57693261', 'NY'],\n",
       "       ['Sep-15', 'Current', ' 36 months', ..., 'Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=59432726', 'PA'],\n",
       "       ...,\n",
       "       ['Jun-15', 'Current', ' 36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=50415990', 'CA'],\n",
       "       ['Apr-15', 'Current', ' 36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=46154151', 'OH'],\n",
       "       ['Dec-15', 'Current', ' 36 months', ..., '',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=66055249', 'IL']],\n",
       "      dtype='<U69')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' data_str: | shape: (10000, 8) | ndim: 2 | size: 80000 | dtype: <U69 '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Empties (''): 3529\n"
     ]
    }
   ],
   "source": [
    "# Reload the data in two dtsets dividing cols in str and num w/usecols\n",
    "## JM no necessary to reload de data_num, we can filter existing data\n",
    "\n",
    "data_str = np.genfromtxt('9_loan-data.csv',\n",
    "                         delimiter=';',\n",
    "                         skip_header=1,\n",
    "                         usecols=cols_str,\n",
    "                         dtype=str)\n",
    "display(data_str)\n",
    "display(show_attr('data_str'))\n",
    "# TypeError: np.isnan in str dtype, then \n",
    "print(\"Num of Empties (''):\", data_str[data_str == \"\"].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    35000.  ,       13.33,     1184.86,     9452.96],\n",
       "       [57693261.  ,    30000.  ,    30000.  , 68616520.  ,      938.57,     4679.7 ],\n",
       "       [59432726.  ,    15000.  ,    15000.  , 68616520.  ,      494.86,     1969.83],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,    10000.  , 68616520.  , 68616520.  ,     2185.64],\n",
       "       [46154151.  , 68616520.  ,    10000.  ,       16.55,      354.3 ,     3199.4 ],\n",
       "       [66055249.  ,    10000.  ,    10000.  , 68616520.  ,      309.97,      301.9 ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' data_num: | shape: (10000, 6) | ndim: 2 | size: 60000 | dtype: float64 '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of NANs: 0\n"
     ]
    }
   ],
   "source": [
    "# Reload the num part of the dtset filling NANs\n",
    "\n",
    "data_num = np.genfromtxt('9_loan-data.csv',\n",
    "                         delimiter=';',\n",
    "                         skip_header=1,\n",
    "                         usecols=cols_num,\n",
    "                         filling_values=temp_fill)\n",
    "display(data_num)\n",
    "display(show_attr('data_num'))\n",
    "print(\"Num of NANs:\", np.isnan(data_num).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8005"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    35000.  ,       13.33,     1184.86,     9452.96],\n",
       "       [57693261.  ,    30000.  ,    30000.  , 68616520.  ,      938.57,     4679.7 ],\n",
       "       [59432726.  ,    15000.  ,    15000.  , 68616520.  ,      494.86,     1969.83],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,    10000.  , 68616520.  , 68616520.  ,     2185.64],\n",
       "       [46154151.  , 68616520.  ,    10000.  ,       16.55,      354.3 ,     3199.4 ],\n",
       "       [66055249.  ,    10000.  ,    10000.  , 68616520.  ,      309.97,      301.9 ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' data_num_jm: | shape: (10000, 6) | ndim: 2 | size: 60000 | dtype: float64 '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of NANs: 0\n",
      "data_num == data_num_jm: True\n"
     ]
    }
   ],
   "source": [
    "# JM way to get data_num without re-read file\n",
    "data_num_jm = raw_data_np[:,cols_num]\n",
    "display(np.isnan(data_num_jm).sum())\n",
    "data_num_jm[np.nonzero(np.isnan(data_num_jm))] = temp_fill\n",
    "# We could have left the NANs and at the time of replacing make the condition (np.isnan())\n",
    "\n",
    "display(data_num_jm)\n",
    "display(show_attr('data_num_jm'))\n",
    "print(\"Num of NANs:\", np.isnan(data_num_jm).sum())\n",
    "print('data_num == data_num_jm:', np.array_equal(data_num, data_num_jm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'issue_d', 'loan_amnt', 'loan_status', 'funded_amnt', 'term', 'int_rate',\n",
       "       'installment', 'grade', 'sub_grade', 'verification_status', 'url', 'addr_state',\n",
       "       'total_pymnt'], dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' header_full: | shape: (14,) | ndim: 1 | size: 14 | dtype: <U19 '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Empties (''): 0\n"
     ]
    }
   ],
   "source": [
    "## The Names of the Columns - get header full\n",
    "header_full = np.genfromtxt('9_loan-data.csv',\n",
    "                           delimiter=';',\n",
    "                           skip_footer=raw_data_np.shape[0],\n",
    "                           dtype=str)\n",
    "display(header_full)\n",
    "display(show_attr('header_full'))\n",
    "# TypeError: np.isnan in str dtype, then \n",
    "print(\"Num of Empties (''):\", header_full[header_full == \"\"].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'issue_d', 'loan_amnt', 'loan_status', 'funded_amnt', 'term', 'int_rate',\n",
       "       'installment', 'grade', 'sub_grade', 'verification_status', 'url', 'addr_state',\n",
       "       'total_pymnt'], dtype='<U69')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' header_full_jm: | shape: (14,) | ndim: 1 | size: 14 | dtype: <U69 '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Empties (''): 0\n",
      "header_full == header_full_jm: True\n"
     ]
    }
   ],
   "source": [
    "### JM way: get only 1st row (data[0])\n",
    "header_full_jm = np.genfromtxt('9_loan-data.csv',\n",
    "                              delimiter=';',\n",
    "                              dtype=str)[0]\n",
    "display(header_full_jm)\n",
    "display(show_attr('header_full_jm'))\n",
    "# TypeError: np.isnan in str dtype, then \n",
    "print(\"Num of Empties (''):\", header_full_jm[header_full_jm == \"\"].size)\n",
    "\n",
    "print('header_full == header_full_jm:', np.array_equal(header_full, header_full_jm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_d', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt'], dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split header_full in header_str and header_num\n",
    "header_str, header_num = header_full[cols_str], header_full[cols_num]\n",
    "display(header_str, header_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating Checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Before we start manipulating the text data, we want to briefly discuss the practice of using checkpoints and how will implement it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkpoints:\n",
    "- Places throughout our code where we store a copy of our dataset (or only parts of it).\n",
    "- Te idea is that we want to avoid losing a lot of progress if we accidentally override the variables we've been working with.\n",
    "- This is an extremely reliable practice when we need to clean or pre-process many parts of a dtset.\n",
    "- Because we're creating a failsafe we can rely on.\n",
    "- def chkpt function in section 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(chkpt_test): <class 'numpy.lib.npyio.NpzFile'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['issue_d', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([['May-15', 'Current', ' 36 months', ..., 'Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=48010226', 'CA'],\n",
       "       ['', 'Current', ' 36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=57693261', 'NY'],\n",
       "       ['Sep-15', 'Current', ' 36 months', ..., 'Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=59432726', 'PA'],\n",
       "       ...,\n",
       "       ['Jun-15', 'Current', ' 36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=50415990', 'CA'],\n",
       "       ['Apr-15', 'Current', ' 36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=46154151', 'OH'],\n",
       "       ['Dec-15', 'Current', ' 36 months', ..., '',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=66055249', 'IL']],\n",
       "      dtype='<U69')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chkpt_test = chkpt('chkpt-test', header_str, data_str)\n",
    "print('type(chkpt_test):', type(chkpt_test))\n",
    "display(chkpt_test['header'])\n",
    "display(chkpt_test['data'])\n",
    "type(chkpt_test['header'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chkpt_test['data'] idem data_str in this case\n",
    "np.array_equal(chkpt_test['data'], data_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Manipulating Text Data: Issue Date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have a column (issue_d). Chack: 9_LoanDatasetDictionary.xlsx\n",
    "- issue_d: The month which the loan was funded. Change to issue_date (more descriptive)\n",
    "- The values of this col are strings (all are -15, year 2015)\n",
    "- We're going to convert characters (str) to numbers(str), eliminating -15 and converting months_names to months_mum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_d', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'issue_d'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0. check the names of the cols in header_str\n",
    "display(header_str)\n",
    "header_str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Transform col name to issue_date (more descriptive)\n",
    "header_str[0] = 'issue_date'\n",
    "header_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'Apr-15', 'Aug-15', 'Dec-15', 'Feb-15', 'Jan-15', 'Jul-15', 'Jun-15', 'Mar-15',\n",
       "       'May-15', 'Nov-15', 'Oct-15', 'Sep-15'], dtype='<U69')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['', 'Apr', 'Aug', 'Dec', 'Feb', 'Jan', 'Jul', 'Jun', 'Mar', 'May', 'Nov', 'Oct', 'Sep'],\n",
       "      dtype='<U69')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['May', '', 'Sep', ..., 'Jun', 'Apr', 'Dec'], dtype='<U69')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. check the unique values of issue_date col and\n",
    "# eliminate '-15' (all are year 2015)\n",
    "display(np.unique(data_str[:,0]))\n",
    "data_str[:,0] = np.chararray.strip(data_str[:,0], '-15')\n",
    "display(np.unique(data_str[:,0]))\n",
    "data_str[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '10', '11', '12', '2', '3', '4', '5', '6', '7', '8', '9'], dtype='<U69')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['5', '0', '9', ..., '6', '4', '12'], dtype='<U69')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Replace the month_name by month_num\n",
    "months = np.array(['', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "                   'Jul', 'Aug', 'Sep', 'Oct', 'Nov','Dec'])\n",
    "\n",
    "for i in range(13):\n",
    "    data_str[:,0] = np.where(data_str[:,0] == months[i],\n",
    "                             i,\n",
    "                             data_str[:,0])\n",
    "    \n",
    "display(np.unique(data_str[:,0]))\n",
    "data_str[:,0]\n",
    "# We won't cast the values to int right away cause we're going to\n",
    "# process al str cols and convert at the end the entire dtset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"06\"></a>\n",
    "## 6. Manipulating Text Data: Loan Status and Term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Continuing examining our str variables (cols) we find 'Loan Status' and 'Term'.\n",
    "- loan_status: we've been told that regressions that determine the probability of default only care if the candidate is in a stable financial condition.\n",
    "- loan_status: should be a simple dummy indicator of whether the applicant is in a good or bad economic state.\n",
    "- loan_status: 'Current', 'Fully Paid', 'In Grace Period', 'Issued',  'Late (16-30 days)' => GOOD = 1 (positive fashion)\n",
    "- loan_status: '', 'Charged Off', 'Default', 'Late (31-120 days)' => BAD = 0 ('' = 0, risk-averse, worst case)'\n",
    "- term: only 3 unique vals: '', ' 36 months', ' 60 months'. We can strip ' months'.\n",
    "- term_months: changed the name and preprocessing only will have 2 vals 36 ans 60.\n",
    "- term_months: when we only have two possible numerical outcomes for a given col -> we could use 1 and 0 instead. Then ask somewhere. Nothing to ask we'll assume that there is a significance to these values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### numpy.isin(element, test_elements, assume_unique=False, invert=False, *, kind=None)\n",
    "- Calculates element in test_elements, broadcasting over element only. Returns a boolean array of the same shape as element that is True where an element of element is in test_elements and False otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['loan_status', 'term'], dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['loan_status', 'term'], dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 0. Let's look at the variables that follow issue_date\n",
    "display(header_str)\n",
    "display(header_str[[1,2]], header_str[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Current', 'Current', 'Current', ..., 'Current', 'Current', 'Current'], dtype='<U69')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['', 'Charged Off', 'Current', 'Default', 'Fully Paid', 'In Grace Period', 'Issued',\n",
       "       'Late (16-30 days)', 'Late (31-120 days)'], dtype='<U69')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' np.unique(data_str[:,1]): | shape: (9,) | ndim: 1 | size: 9 | dtype: <U69 '"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1a. Let's look the data in 'loan_status' \n",
    "display(data_str[:,1])\n",
    "display(np.unique(data_str[:,1]))\n",
    "show_attr('np.unique(data_str[:,1])')\n",
    "# 9 diff vals for individual els of this col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '1', '1', ..., '1', '1', '1'], dtype='<U69')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['0', '1'], dtype='<U69')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2a. Replace the vals for 1 or 0 if their are GOOD or BAD loan_status\n",
    "bad = np.array(['', 'Charged Off', 'Default', 'Late (31-120 days)'])\n",
    "data_str[:,1] = np.where(np.isin(data_str[:,1], bad), 0, 1)\n",
    "# Check\n",
    "display(data_str[:,1])\n",
    "display(np.unique(data_str[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' 36 months', ' 36 months', ' 36 months', ..., ' 36 months', ' 36 months', ' 36 months'],\n",
       "      dtype='<U69')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['', ' 36 months', ' 60 months'], dtype='<U69')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' np.unique(data_str[:,2]): | shape: (3,) | ndim: 1 | size: 3 | dtype: <U69 '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1b. Let's look the data in 'term' \n",
    "display(data_str[:,2])\n",
    "display(np.unique(data_str[:,2]))\n",
    "show_attr('np.unique(data_str[:,2])')\n",
    "# 3 diff vals for individual els of this col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['36', '36', '36', ..., '36', '36', '36'], dtype='<U69')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['', '36', '60'], dtype='<U69')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_months', 'grade', 'sub_grade', 'verification_status',\n",
       "       'url', 'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2b. strip ' months' and change col name to indicates num are months\n",
    "data_str[:,2] = np.chararray.strip(data_str[:,2], ' months')\n",
    "display(data_str[:,2])\n",
    "display(np.unique(data_str[:,2]))\n",
    "\n",
    "# change col name to indicates num are months\n",
    "header_str[2] = 'term_months'\n",
    "header_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['36', '60'], dtype='<U69')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3b. assign 60 (worst case) to empties\n",
    "data_str[:,2] = np.where(data_str[:,2] == '',\n",
    "                         '60',                # assume the worst\n",
    "                         data_str[:,2])\n",
    "np.unique(data_str[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"07\"></a>\n",
    "## 7. Manipulating Text Data: Grade and Sub Grade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Next to columns 'grade' and 'sub_grade'\n",
    "- Uniques 'grade': '', 'A', 'B', 'C', 'D', 'E', 'F', 'G'\n",
    "- Uniques 'sub_grade': '', 'A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C1', 'C2', 'C3', 'C4','C5', 'D1','D2', 'D3', 'D4', 'D5', 'E1', 'E2', 'E3', 'E4', 'E5', 'F1', 'F2','F3', 'F4', 'F5', 'G1', 'G2', 'G3', 'G4', 'G5'\n",
    "- For e/el we saw in grade, we have 5 diff els in sub_grade\n",
    "- If the data is complete any info we can get from 'grade' col can also be obtained from the 'sub_grade' col.\n",
    "- That in theory makes 'grade' redundant (not always the case).\n",
    "- When there are missing els in sub_grade, we can use grade to assign more appropriate estimations.\n",
    "- Ex. if the sub_grade for an account is missing but the grade is B, it makes more sense to assign to ir a sub_grade B5 rather than the worst possible grade (G5).\n",
    "- After replacing the '' in sub_grade (referring grade values) we still have 9 of them left. 9 in 10000 is relatively nothing. We could drop this vals. \n",
    "- There is something better we could do (our job requires us to assign status to every individual): create a whole new category lower than G5 (precautionary step cause accounts which are withholding info must be penalized accordingly).\n",
    "- The info in grade will stay in sub_grade then we can remove 'grade' col.\n",
    "- Then we'll replace categorical(s) of sub_grade by numbers using a dic constructed w/zip Python function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### zip(*iterables)\n",
    "- Make an iterator that aggregates elements from each of the iterables.\n",
    "- Returns an iterator of tuples, where the i-th tuple contains the i-th element from each of the argument sequences or iterables. The iterator stops when the shortest input iterable is exhausted. With a single iterable argument, it returns an iterator of 1-tuples. With no arguments, it returns an empty iterator. Equivalent to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_months', 'grade', 'sub_grade', 'verification_status',\n",
       "       'url', 'addr_state'], dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['grade', 'sub_grade'], dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([['C', 'C3'],\n",
       "       ['A', 'A5'],\n",
       "       ['B', 'B5'],\n",
       "       ...,\n",
       "       ['A', 'A5'],\n",
       "       ['D', 'D2'],\n",
       "       ['A', 'A4']], dtype='<U69')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "8 uniques of 'grade':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['', 'A', 'B', 'C', 'D', 'E', 'F', 'G'], dtype='<U69')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "36 uniques of 'sub_grade':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['', 'A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C1', 'C2', 'C3', 'C4',\n",
       "       'C5', 'D1', 'D2', 'D3', 'D4', 'D5', 'E1', 'E2', 'E3', 'E4', 'E5', 'F1', 'F2', 'F3', 'F4',\n",
       "       'F5', 'G1', 'G2', 'G3', 'G4', 'G5'], dtype='<U69')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 0. Let's see the headers and contents of grade and sub_grade\n",
    "display(header_str)\n",
    "display(header_str[3:5])\n",
    "\n",
    "display(data_str[:,3:5])    # same display(data_str[:,[3,4]])\n",
    "# display(np.unique(data_str[:,3]))\n",
    "# display(np.unique(data_str[:,4]))\n",
    "\n",
    "for i in (3,4):\n",
    "    uniques = np.unique(data_str[:,i])\n",
    "    print(f\"{'-' * 30}\\n{uniques.size} uniques of '{header_str[i]}':\")\n",
    "    display(uniques)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "514"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([31], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "514"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "grade sub_grade\n",
      "['D' '']\n",
      "['B' '']\n",
      "['D' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['D' '']\n",
      "['B' '']\n",
      "['F' '']\n",
      "['C' '']\n",
      "['D' '']\n",
      "['B' '']\n",
      "['G' '']\n",
      "['B' '']\n",
      "['' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['' '']\n",
      "['D' '']\n",
      "['' '']\n",
      "['A' '']\n",
      "['A' '']\n",
      "['F' '']\n",
      "['E' '']\n",
      "['A' '']\n",
      "['A' '']\n",
      "['' '']\n",
      "['D' '']\n",
      "['D' '']\n",
      "['C' '']\n",
      "['A' '']\n",
      "['A' '']\n",
      "['B' '']\n",
      "['A' '']\n",
      "['B' '']\n",
      "['D' '']\n",
      "['E' '']\n",
      "['A' '']\n",
      "['A' '']\n",
      "['B' '']\n",
      "['A' '']\n",
      "['B' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['A' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['B' '']\n",
      "['A' '']\n",
      "['B' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['E' '']\n",
      "['' '']\n",
      "['C' '']\n",
      "['D' '']\n",
      "['B' '']\n",
      "['E' '']\n",
      "['D' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['A' '']\n",
      "['A' '']\n",
      "['D' '']\n",
      "['A' '']\n",
      "['E' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['C' '']\n",
      "['A' '']\n",
      "['C' '']\n",
      "['B' '']\n",
      "['C' '']\n",
      "['D' '']\n",
      "['E' '']\n",
      "['D' '']\n",
      "['C' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['A' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['A' '']\n",
      "['E' '']\n",
      "['C' '']\n",
      "['B' '']\n",
      "['A' '']\n",
      "['A' '']\n",
      "['E' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['E' '']\n",
      "['D' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['E' '']\n",
      "['B' '']\n",
      "['D' '']\n",
      "['E' '']\n",
      "['C' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['B' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['A' '']\n",
      "['C' '']\n",
      "['A' '']\n",
      "['F' '']\n",
      "['E' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['D' '']\n",
      "['B' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['D' '']\n",
      "['D' '']\n",
      "['B' '']\n",
      "['C' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['C' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['C' '']\n",
      "['E' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['B' '']\n",
      "['E' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['C' '']\n",
      "['B' '']\n",
      "['A' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['C' '']\n",
      "['B' '']\n",
      "['A' '']\n",
      "['A' '']\n",
      "['E' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['E' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['A' '']\n",
      "['A' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['A' '']\n",
      "['C' '']\n",
      "['A' '']\n",
      "['A' '']\n",
      "['C' '']\n",
      "['B' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['E' '']\n",
      "['C' '']\n",
      "['B' '']\n",
      "['C' '']\n",
      "['B' '']\n",
      "['D' '']\n",
      "['F' '']\n",
      "['B' '']\n",
      "['A' '']\n",
      "['C' '']\n",
      "['E' '']\n",
      "['A' '']\n",
      "['A' '']\n",
      "['C' '']\n",
      "['B' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['A' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['B' '']\n",
      "['D' '']\n",
      "['E' '']\n",
      "['G' '']\n",
      "['D' '']\n",
      "['A' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['A' '']\n",
      "['B' '']\n",
      "['E' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['A' '']\n",
      "['B' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['A' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['C' '']\n",
      "['D' '']\n",
      "['D' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['E' '']\n",
      "['A' '']\n",
      "['C' '']\n",
      "['G' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['C' '']\n",
      "['A' '']\n",
      "['D' '']\n",
      "['B' '']\n",
      "['A' '']\n",
      "['A' '']\n",
      "['C' '']\n",
      "['A' '']\n",
      "['E' '']\n",
      "['C' '']\n",
      "['D' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['A' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['C' '']\n",
      "['D' '']\n",
      "['B' '']\n",
      "['F' '']\n",
      "['C' '']\n",
      "['E' '']\n",
      "['D' '']\n",
      "['B' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['B' '']\n",
      "['A' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['B' '']\n",
      "['D' '']\n",
      "['C' '']\n",
      "['A' '']\n",
      "['A' '']\n",
      "['C' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['D' '']\n",
      "['A' '']\n",
      "['A' '']\n",
      "['C' '']\n",
      "['B' '']\n",
      "['D' '']\n",
      "['C' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['C' '']\n",
      "['D' '']\n",
      "['C' '']\n",
      "['D' '']\n",
      "['C' '']\n",
      "['A' '']\n",
      "['B' '']\n",
      "['A' '']\n",
      "['A' '']\n",
      "['E' '']\n",
      "['D' '']\n",
      "['C' '']\n",
      "['A' '']\n",
      "['C' '']\n",
      "['A' '']\n",
      "['D' '']\n",
      "['A' '']\n",
      "['E' '']\n",
      "['E' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['D' '']\n",
      "['E' '']\n",
      "['A' '']\n",
      "['B' '']\n",
      "['A' '']\n",
      "['D' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['E' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['E' '']\n",
      "['B' '']\n",
      "['A' '']\n",
      "['D' '']\n",
      "['E' '']\n",
      "['D' '']\n",
      "['B' '']\n",
      "['A' '']\n",
      "['C' '']\n",
      "['A' '']\n",
      "['C' '']\n",
      "['A' '']\n",
      "['E' '']\n",
      "['A' '']\n",
      "['B' '']\n",
      "['C' '']\n",
      "['A' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['A' '']\n",
      "['C' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['C' '']\n",
      "['B' '']\n",
      "['E' '']\n",
      "['C' '']\n",
      "['A' '']\n",
      "['C' '']\n",
      "['' '']\n",
      "['C' '']\n",
      "['' '']\n",
      "['D' '']\n",
      "['C' '']\n",
      "['A' '']\n",
      "['D' '']\n",
      "['C' '']\n",
      "['' '']\n",
      "['D' '']\n",
      "['' '']\n",
      "['C' '']\n",
      "['A' '']\n",
      "['A' '']\n",
      "['B' '']\n",
      "['D' '']\n",
      "['A' '']\n",
      "['C' '']\n",
      "['D' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['C' '']\n",
      "['E' '']\n",
      "['E' '']\n",
      "['C' '']\n",
      "['B' '']\n",
      "['D' '']\n",
      "['A' '']\n",
      "['D' '']\n",
      "['F' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['C' '']\n",
      "['A' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['B' '']\n",
      "['C' '']\n",
      "['D' '']\n",
      "['C' '']\n",
      "['B' '']\n",
      "['C' '']\n",
      "['D' '']\n",
      "['A' '']\n",
      "['B' '']\n",
      "['F' '']\n",
      "['A' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['B' '']\n",
      "['D' '']\n",
      "['B' '']\n",
      "['D' '']\n",
      "['E' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['A' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['E' '']\n",
      "['D' '']\n",
      "['E' '']\n",
      "['B' '']\n",
      "['E' '']\n",
      "['C' '']\n",
      "['B' '']\n",
      "['D' '']\n",
      "['B' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['B' '']\n",
      "['E' '']\n",
      "['E' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['E' '']\n",
      "['C' '']\n",
      "['D' '']\n",
      "['A' '']\n",
      "['D' '']\n",
      "['A' '']\n",
      "['A' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['A' '']\n",
      "['B' '']\n",
      "['D' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['E' '']\n",
      "['B' '']\n",
      "['C' '']\n",
      "['A' '']\n",
      "['D' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['B' '']\n",
      "['D' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['E' '']\n",
      "['D' '']\n",
      "['A' '']\n",
      "['D' '']\n",
      "['B' '']\n",
      "['D' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['E' '']\n",
      "['B' '']\n",
      "['A' '']\n",
      "['A' '']\n",
      "['C' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['A' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['C' '']\n",
      "['D' '']\n",
      "['E' '']\n",
      "['B' '']\n",
      "['A' '']\n",
      "['B' '']\n",
      "['A' '']\n",
      "['B' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['B' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['D' '']\n",
      "['D' '']\n",
      "['C' '']\n",
      "['B' '']\n",
      "['A' '']\n",
      "['D' '']\n",
      "['C' '']\n",
      "['F' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['B' '']\n",
      "['A' '']\n",
      "['A' '']\n",
      "['B' '']\n",
      "['C' '']\n",
      "['B' '']\n",
      "['C' '']\n",
      "['B' '']\n",
      "['B' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['C' '']\n",
      "['D' '']\n",
      "['B' '']\n",
      "['A' '']\n",
      "['E' '']\n",
      "['A' '']\n",
      "['D' '']\n"
     ]
    }
   ],
   "source": [
    "# 1. Let's see some data related w/the '' in sub_grade\n",
    "\n",
    "display((data_str[:,4] == '').sum())            # num of '' in sub_grade\n",
    "np.argwhere(data_str[:,4] == '')                # Ixs of '' un sub_grade\n",
    "display(np.argwhere(data_str[:,4] == '')[0])    # 1st appearance of ''\n",
    "\n",
    "# display(np.unique(data_str[:,4], return_index=True, return_counts=True))\n",
    "unique_arrays = np.unique(data_str[:,4], return_index=True, return_counts=True)\n",
    "# display(unique_arrays)\n",
    "# W/unique show only 1st el ('') of all arrays\n",
    "for i in range(len(unique_arrays)):\n",
    "    display(unique_arrays[i][0])\n",
    "print()\n",
    "\n",
    "# Show all rows (cols 3,4) where sub_grade (col4) = ''\n",
    "print('grade', 'sub_grade')\n",
    "for row in np.argwhere(data_str[:,4] == ''):\n",
    "    print(data_str[row, 3:5].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Let's substitute the empty spaces in sub_grade with the help of grade\n",
    "for gd in np.unique(data_str[:,3])[1:]:\n",
    "    data_str[:,4] = np.where((data_str[:,4] == '') & (data_str[:,3] == gd),\n",
    "                             gd + '5',      # risk-adverse, '5' worst case\n",
    "                             data_str[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([222], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "222"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "grade sub_grade\n",
      "['' '']\n",
      "['' '']\n",
      "['' '']\n",
      "['' '']\n",
      "['' '']\n",
      "['' '']\n",
      "['' '']\n",
      "['' '']\n",
      "['' '']\n"
     ]
    }
   ],
   "source": [
    "# 3. Lets check w/ 1. readings.\n",
    "display((data_str[:,4] == '').sum())            # num of '' in sub_grade\n",
    "np.argwhere(data_str[:,4] == '')                # Ixs of '' un sub_grade\n",
    "display(np.argwhere(data_str[:,4] == '')[0])    # 1st appearance of ''\n",
    "\n",
    "# display(np.unique(data_str[:,4], return_index=True, return_counts=True))\n",
    "unique_arrays = np.unique(data_str[:,4], return_index=True, return_counts=True)\n",
    "# display(unique_arrays)\n",
    "# W/unique show only 1st el ('') of all arrays\n",
    "for i in range(len(unique_arrays)):\n",
    "    display(unique_arrays[i][0])\n",
    "print()\n",
    "\n",
    "# Show all rows (cols 3,4) where sub_grade (col4) = ''\n",
    "print('grade', 'sub_grade')\n",
    "for row in np.argwhere(data_str[:,4] == ''):\n",
    "    print(data_str[row, 3:5].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C1', 'C2', 'C3', 'C4', 'C5',\n",
       "        'D1', 'D2', 'D3', 'D4', 'D5', 'E1', 'E2', 'E3', 'E4', 'E5', 'F1', 'F2', 'F3', 'F4', 'F5',\n",
       "        'G1', 'G2', 'G3', 'G4', 'G5', 'H1'], dtype='<U69'),\n",
       " array([ 102,   23,  190,   19,    1,   44,   21,   59,   33,    2,   11,    9,    0,    5,   83,\n",
       "          10,   85,   30,   55,   15,   93,   76,    4,   16,   37,   34,   50,   86,    6,   87,\n",
       "         208,  447, 1138, 1732,  178,  222], dtype=int64),\n",
       " array([285, 278, 239, 323, 592, 509, 517, 530, 553, 633, 629, 567, 586, 564, 577, 391, 267, 250,\n",
       "        255, 288, 235, 162, 171, 139, 160,  94,  52,  34,  43,  24,  19,  10,   3,   7,   5,   9],\n",
       "       dtype=int64))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Replace the remaining '' in sub_grade w/cat H1 (worst of G5)\n",
    "data_str[:,4] = np.where(data_str[:,4] == '', 'H1', data_str[:,4])\n",
    "np.unique(data_str[:,4], return_index=True, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C3', 'A5', 'B5', ..., 'A5', 'D2', 'A4'], dtype='<U69')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_months', 'sub_grade', 'verification_status', 'url',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5. Remove 'grade' from data and header\n",
    "data_str = np.delete(data_str, 3, axis=1)\n",
    "header_str = np.delete(header_str, 3)\n",
    "display(data_str[:,3], header_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C1', 'C2', 'C3', 'C4', 'C5',\n",
       "       'D1', 'D2', 'D3', 'D4', 'D5', 'E1', 'E2', 'E3', 'E4', 'E5', 'F1', 'F2', 'F3', 'F4', 'F5',\n",
       "       'G1', 'G2', 'G3', 'G4', 'G5', 'H1'], dtype='<U69')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23,\n",
       "       24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22',\n",
       "       '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36',\n",
       "       '4', '5', '6', '7', '8', '9'], dtype='<U69')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Replace sub_grade cats by numbers w/dic build w/zip Python function.\n",
    "keys = np.unique(data_str[:,3])\n",
    "# values = [i for i in range(1, np.unique(data_str[:,3]).size + 1)]\n",
    "# values = list(range(1, np.unique(data_str[:,3]).size + 1))\n",
    "values = np.arange(1, np.unique(data_str[:,3]).size + 1)\n",
    "display (keys, values)\n",
    "dic_sub_gd = dict(zip(keys, values))    # {'A1':1, 'A2':2, ...} is created\n",
    "dic_sub_gd  \n",
    "\n",
    "# for k,v in dic_sub_gd.items():\n",
    "#     data_str[:,3] = np.where(data_str[:,3] == k, v, data_str[:,3])\n",
    "\n",
    "for k in np.unique(data_str[:,3]):\n",
    "    data_str[:,3] = np.where(data_str[:,3] == k,\n",
    "                             dic_sub_gd[k],\n",
    "                             data_str[:,3])\n",
    "\n",
    "\n",
    "data_str[:,3]\n",
    "np.unique(data_str[:,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"08\"></a>\n",
    "## 8. Manipulating Text Data: Verification Status & URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- verification_status: convert to dummy 0,1 - bad, good. np.where(cond, 0,1)\n",
    "- url: observe the content. Discover same url change fuinal num, strip the text, see the num = a data_num'id', arr_equal .astype int 32 True. DECIDE to ELIMINATE url (of course form data an header)\n",
    "- check data_num'id' not change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_months', 'sub_grade', 'verification_status', 'url',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([4], dtype=int64),)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[4]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'verification_status'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['Verified', 'Source Verified', 'Verified', ..., 'Source Verified', 'Source Verified', ''],\n",
       "      dtype='<U69')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array(['', 'Not Verified', 'Source Verified', 'Verified'], dtype='<U69'),\n",
       " array([7, 3, 1, 0], dtype=int64),\n",
       " array([ 500, 2673, 4116, 2711], dtype=int64))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0. Let's check the headers and data\n",
    "display(header_str)\n",
    "display(np.where(header_str == 'verification_status'))\n",
    "display(np.argwhere(header_str == 'verification_status'))\n",
    "\n",
    "display(header_str[4], data_str[:,4])\n",
    "np.unique(data_str[:,4], return_index=True, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'verification_status'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['1', '1', '1', ..., '1', '1', '0'], dtype='<U69')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array(['0', '1'], dtype='<U69'),\n",
       " array([3, 0], dtype=int64),\n",
       " array([3173, 6827], dtype=int64))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Makes dummies: replace unique of verification_statu by 0, 1\n",
    "# 1 = Good = 'Source Verified', 'Verified'; 0, Bad: '', 'Not Verified'.\n",
    "data_str[:,4] = np.where((data_str[:,4] == '') |\n",
    "                         (data_str[:,4] == 'Not Verified'),\n",
    "                         0,\n",
    "                         1)\n",
    "\n",
    "display(header_str[4], data_str[:,4])\n",
    "np.unique(data_str[:,4], return_index=True, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['https://www.lendingclub.com/browse/loanDetail.action?loan_id=48010226',\n",
       "       'https://www.lendingclub.com/browse/loanDetail.action?loan_id=57693261',\n",
       "       'https://www.lendingclub.com/browse/loanDetail.action?loan_id=59432726', ...,\n",
       "       'https://www.lendingclub.com/browse/loanDetail.action?loan_id=50415990',\n",
       "       'https://www.lendingclub.com/browse/loanDetail.action?loan_id=46154151',\n",
       "       'https://www.lendingclub.com/browse/loanDetail.action?loan_id=66055249'], dtype='<U69')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. Look url column (field)\n",
    "display(np.argwhere(header_str == 'url'))\n",
    "display(data_str[:,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['48010226', '57693261', '59432726', ..., '50415990', '46154151', '66055249'], dtype='<U69')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([48010226., 57693261., 59432726., ..., 50415990., 46154151., 66055249.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Lets get rid of text, leave only numbers (pay attention 'loan-id=')\n",
    "data_str[:,5] = np.chararray.strip(data_str[:,5],\n",
    "                   'https://www.lendingclub.com/browse/loanDetail.action?loan_id=')\n",
    "display(data_str[:,5])\n",
    "\n",
    "# loan_id idem to data_num['id]?\n",
    "display(np.argwhere(header_num == 'id'))\n",
    "display(data_num[:,0])\n",
    "\n",
    "# Check comparing with the same dtype\n",
    "np.array_equal(data_str[:,5].astype(np.int32), data_num[:,0].astype(np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_months', 'sub_grade', 'verification_status',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([['5', '1', '36', '13', '1', 'CA'],\n",
       "       ['0', '1', '36', '5', '1', 'NY'],\n",
       "       ['9', '1', '36', '10', '1', 'PA'],\n",
       "       ...,\n",
       "       ['6', '1', '36', '5', '1', 'CA'],\n",
       "       ['4', '1', '36', '17', '1', 'OH'],\n",
       "       ['12', '1', '36', '4', '0', 'IL']], dtype='<U69')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4. Delete url (data and header) all data is in data_num['id']\n",
    "display(header_str := np.delete(header_str, 5))\n",
    "display(data_str := np.delete(data_str, 5, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48010226., 57693261., 59432726., ..., 50415990., 46154151., 66055249.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 Recheck data_num[:,0] 'id' to see the values hasn't change\n",
    "data_num[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Manipulating Text Data: State Address\n",
    "<a id=\"09\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 'addr_state' change to 'state_address: There are exactly 50 states in the USA.\n",
    "- IOWA - IA is not in the data: we suspect that it was purposely left as a __*baseline benchmark*__\n",
    "- (This shouldn't come as a big surprise). When doing research or analysis on a variable with many categories, it is normal to pick one as a benchmark and include dummy variables for the rest.\n",
    "- With such an approach the one without a dummy variable (IA) will serve as the base case and we will either increase or decrease the rest based on their coefficients.\n",
    "- We'll assume this was IA. We can also see how many times each state features in the column.\n",
    "- Using argsort we sort the uniques according to the number or applicants (decreasing) from e/one.\n",
    "- Most of the accounts come from highly populated and wealthy states like CA, NY, TX and FL -> The four states with more accounts than the '', => there are mor applications with missing or unreported addresses than there are for 45 of the other states.\n",
    "- We have very little data for too many states to examine each one individually, then if we assign a unique val to each state, this will allow outliers to have a big influence on the coefficients to less representative states.\n",
    "- The mode categories a variable has, the fewer data will be available for each one: the states with fewer applications will be more vulnerable to have their coefficients affected by outliers.\n",
    "- To solve this problem, se need to group these states according to a certain common characteristics -> Geographical location: west, south, midwest, east."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_months', 'sub_grade', 'verification_status',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[5]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['CA', 'NY', 'PA', ..., 'CA', 'OH', 'IL'], dtype='<U69')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Num of '': 500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array(['', 'AK', 'AL', 'AR', 'AZ', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA', 'HI', 'IL', 'IN',\n",
       "        'KS', 'KY', 'LA', 'MA', 'MD', 'ME', 'MI', 'MN', 'MO', 'MS', 'MT', 'NC', 'ND', 'NE', 'NH',\n",
       "        'NJ', 'NM', 'NV', 'NY', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VA',\n",
       "        'VT', 'WA', 'WI', 'WV', 'WY'], dtype='<U69'),\n",
       " array([ 500,   26,  119,   74,  220, 1336,  201,  143,   27,   27,  690,  321,   44,  389,  152,\n",
       "          84,   84,  116,  210,  222,   10,  267,  156,  160,   61,   28,  261,   16,   25,   58,\n",
       "         341,   57,  130,  777,  312,   83,  108,  320,   40,  107,   24,  143,  758,   74,  242,\n",
       "          17,  216,  148,   49,   27], dtype=int64))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0. Look the headers and content of col of interest\n",
    "display(header_str)\n",
    "display(np.argwhere(header_str =='addr_state'))\n",
    "header_str[5] = 'state_address'\n",
    "display(data_str[:,5])\n",
    "# display(np.unique(data_str[:,5]))\n",
    "print(f\" Num of '': {data_str[data_str == ''].size}\")\n",
    "np.unique(data_str[:,5], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_months', 'sub_grade', 'verification_status',\n",
       "       'state_address'], dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 5, 33, 42, 10,  0, 13, 30, 11, 37, 34, 21, 26, 44, 19,  4, 46, 18,  6, 23, 22, 14, 47,  7,\n",
       "       41, 32,  2, 17, 36, 39, 16, 15, 35, 43,  3, 24, 29, 31, 48, 12, 38, 25,  9,  8, 49,  1, 28,\n",
       "       40, 45, 27, 20], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array(['CA', 'NY', 'TX', 'FL', '', 'IL', 'NJ', 'GA', 'PA', 'OH', 'MI', 'NC', 'VA', 'MD', 'AZ',\n",
       "        'WA', 'MA', 'CO', 'MO', 'MN', 'IN', 'WI', 'CT', 'TN', 'NV', 'AL', 'LA', 'OR', 'SC', 'KY',\n",
       "        'KS', 'OK', 'UT', 'AR', 'MS', 'NH', 'NM', 'WV', 'HI', 'RI', 'MT', 'DE', 'DC', 'WY', 'AK',\n",
       "        'NE', 'SD', 'VT', 'ND', 'ME'], dtype='<U69'),\n",
       " array([1336,  777,  758,  690,  500,  389,  341,  321,  320,  312,  267,  261,  242,  222,  220,\n",
       "         216,  210,  201,  160,  156,  152,  148,  143,  143,  130,  119,  116,  108,  107,   84,\n",
       "          84,   83,   74,   74,   61,   58,   57,   49,   44,   40,   28,   27,   27,   27,   26,\n",
       "          25,   24,   17,   16,   10], dtype=int64))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Sort in crescent order or appearance\n",
    "display(header_str)\n",
    "st_names, st_counts = np.unique(data_str[:,5], return_counts=True)\n",
    "# display(st_names, st_counts)\n",
    "# display(np.sort(-st_counts))\n",
    "st_counts_sort_ixs = np.argsort(-st_counts)\n",
    "display(st_counts_sort_ixs)\n",
    "st_names[st_counts_sort_ixs], st_counts[st_counts_sort_ixs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_months', 'sub_grade', 'verification_status',\n",
       "       'state_address'], dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'': 500, 'AK': 26, 'AL': 119, 'AR': 74, 'AZ': 220, 'CA': 1336, 'CO': 201, 'CT': 143, 'DC': 27, 'DE': 27, 'FL': 690, 'GA': 321, 'HI': 44, 'IL': 389, 'IN': 152, 'KS': 84, 'KY': 84, 'LA': 116, 'MA': 210, 'MD': 222, 'ME': 10, 'MI': 267, 'MN': 156, 'MO': 160, 'MS': 61, 'MT': 28, 'NC': 261, 'ND': 16, 'NE': 25, 'NH': 58, 'NJ': 341, 'NM': 57, 'NV': 130, 'NY': 777, 'OH': 312, 'OK': 83, 'OR': 108, 'PA': 320, 'RI': 40, 'SC': 107, 'SD': 24, 'TN': 143, 'TX': 758, 'UT': 74, 'VA': 242, 'VT': 17, 'WA': 216, 'WI': 148, 'WV': 49, 'WY': 27}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1336,  777,  758,  690,  500,  389,  341,  321,  320,  312,  267,  261,  242,  222,  220,\n",
       "        216,  210,  201,  160,  156,  152,  148,  143,  143,  130,  119,  116,  108,  107,   84,\n",
       "         84,   83,   74,   74,   61,   58,   57,   49,   44,   40,   28,   27,   27,   27,   26,\n",
       "         25,   24,   17,   16,   10], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CA': 1336, 'NY': 777, 'TX': 758, 'FL': 690, '': 500, 'IL': 389, 'NJ': 341, 'GA': 321, 'PA': 320, 'OH': 312, 'MI': 267, 'NC': 261, 'VA': 242, 'MD': 222, 'AZ': 220, 'WA': 216, 'MA': 210, 'CO': 201, 'MO': 160, 'MN': 156, 'IN': 152, 'WI': 148, 'CT': 143, 'TN': 143, 'NV': 130, 'AL': 119, 'LA': 116, 'OR': 108, 'SC': 107, 'KS': 84, 'KY': 84, 'OK': 83, 'AR': 74, 'UT': 74, 'MS': 61, 'NH': 58, 'NM': 57, 'WV': 49, 'HI': 44, 'RI': 40, 'MT': 28, 'DC': 27, 'DE': 27, 'WY': 27, 'AK': 26, 'NE': 25, 'SD': 24, 'VT': 17, 'ND': 16, 'ME': 10}\n"
     ]
    }
   ],
   "source": [
    "# 1b. JM dic method - Sort in crescent order or appearance\n",
    "display(header_str)\n",
    "uniq_st_add = np.unique(data_str[:,5], return_counts=True)\n",
    "dic_stadd_frec = dict(zip(uniq_st_add[0], uniq_st_add[1]))\n",
    "print(dic_stadd_frec)\n",
    "\n",
    "# display(~np.sort(~uniq_st_add[1]))\n",
    "display(-np.sort(-uniq_st_add[1]))\n",
    "# print(sorted(uniq_st_add[1], reverse=True))\n",
    "# print(sorted(dic_stadd_frec.values(), reverse=True))\n",
    "# display(np.sort(dic_stadd_frec.values()))   # AxisError\n",
    "# print(dic_stadd_frec.values(), type(dic_stadd_frec.values()))\n",
    "\n",
    "dic_stadd_fcy = dict()\n",
    "for count in -np.sort(-uniq_st_add[1]):\n",
    "    for k,v in dic_stadd_frec.items():\n",
    "        if v == count:\n",
    "            dic_stadd_fcy[k] = v\n",
    "\n",
    "print(dic_stadd_fcy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['0', 'AK', 'AL', 'AR', 'AZ', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA', 'HI', 'IL', 'IN',\n",
       "        'KS', 'KY', 'LA', 'MA', 'MD', 'ME', 'MI', 'MN', 'MO', 'MS', 'MT', 'NC', 'ND', 'NE', 'NH',\n",
       "        'NJ', 'NM', 'NV', 'NY', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VA',\n",
       "        'VT', 'WA', 'WI', 'WV', 'WY'], dtype='<U69'),\n",
       " array([ 500,   26,  119,   74,  220, 1336,  201,  143,   27,   27,  690,  321,   44,  389,  152,\n",
       "          84,   84,  116,  210,  222,   10,  267,  156,  160,   61,   28,  261,   16,   25,   58,\n",
       "         341,   57,  130,  777,  312,   83,  108,  320,   40,  107,   24,  143,  758,   74,  242,\n",
       "          17,  216,  148,   49,   27], dtype=int64))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Let's take care of empty vals ('') -> assign 0 to not enter any category\n",
    "data_str[:,5] = np.where(data_str[:,5] == '', 0, data_str[:,5])\n",
    "np.unique(data_str[:,5], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['0', '1', '2', '3', '4'], dtype='<U69'),\n",
       " array([ 500, 2467, 3384, 1733, 1916], dtype=int64))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Group the states according geographical location.\n",
    "states_west = np.array(['WA', 'OR','CA','NV','ID','MT', 'WY','UT','CO', 'AZ','NM','HI','AK'])\n",
    "states_south = np.array(['TX','OK','AR','LA','MS','AL','TN','KY','FL','GA','SC','NC','VA','WV','MD','DE','DC'])\n",
    "states_midwest = np.array(['ND','SD','NE','KS','MN','IA','MO','WI','IL','IN','MI','OH'])\n",
    "states_east = np.array(['PA','NY','NJ','CT','MA','VT','NH','ME','RI'])\n",
    "\n",
    "cnt = 1\n",
    "for region in (states_west, states_south, states_midwest, states_east):\n",
    "    data_str[:,5] = np.where(np.isin(data_str[:,5], region), cnt, data_str[:,5])\n",
    "    cnt += 1\n",
    "\n",
    "np.unique(data_str[:,5], return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Manipulating Text Data: Converting Strings and Creating a Checkpoint\n",
    "<a id=\"10\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have all data_str vals in numeric fashion but still are str, then que need to convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['5', '1', '36', '13', '1', '1'],\n",
       "       ['0', '1', '36', '5', '1', '4'],\n",
       "       ['9', '1', '36', '10', '1', '4'],\n",
       "       ...,\n",
       "       ['6', '1', '36', '5', '1', '1'],\n",
       "       ['4', '1', '36', '17', '1', '3'],\n",
       "       ['12', '1', '36', '4', '0', '3']], dtype='<U69')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0. Let's look the data\n",
    "data_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  1, 36, 13,  1,  1],\n",
       "       [ 0,  1, 36,  5,  1,  4],\n",
       "       [ 9,  1, 36, 10,  1,  4],\n",
       "       ...,\n",
       "       [ 6,  1, 36,  5,  1,  1],\n",
       "       [ 4,  1, 36, 17,  1,  3],\n",
       "       [12,  1, 36,  4,  0,  3]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' data_str: | shape: (10000, 6) | ndim: 2 | size: 60000 | dtype: int32 '"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Cast to numeric type (int)\n",
    "data_str = data_str.astype(int)\n",
    "display(data_str)\n",
    "show_attr('data_str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_months', 'sub_grade', 'verification_status',\n",
       "       'state_address'], dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 5,  1, 36, 13,  1,  1],\n",
       "       [ 0,  1, 36,  5,  1,  4],\n",
       "       [ 9,  1, 36, 10,  1,  4],\n",
       "       ...,\n",
       "       [ 6,  1, 36,  5,  1,  1],\n",
       "       [ 4,  1, 36, 17,  1,  3],\n",
       "       [12,  1, 36,  4,  0,  3]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Create the checkpoint and check it\n",
    "chkpt_str = chkpt('chkpt-str', header_str, data_str)\n",
    "display(chkpt_str['header'], chkpt_str['data'])\n",
    "np.array_equal(chkpt_str['data'], data_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Manipulating Numeric Data: Substitute Filler Values\n",
    "<a id=\"11\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here we have to recall (remember) the temp_fill and orig_stats we calc early\n",
    "- It suppose 'id' won't have missings (temp_fill) <- check>\n",
    "#### Rest of cols_num will be filled w/min and max depending:\n",
    "- 'loan_amnt': 1,000 - 35,000. Worst -> Max. Can be of any size according to the Bank's current abilities.\n",
    "- Loan Amount: The listed amount of the loan applied for by the borrower. If at some point in time, the credit department reduces the loan amount, then it will be reflected in this value (El importe del prstamo solicitado por el prestatario. Si en algn momento el departamento de crdito reduce el importe del prstamo, esto se reflejar en este valor.)\n",
    "\n",
    "- 'int_rate': 6 - 28.99. Worst -> Max. Varies according to the loan amount and credit risk status of the individual or business taking the loan.\n",
    "- Interest Rate: Interest Rate on the loan (Tasa de inters del prstamo)\n",
    "\n",
    "- 'installment': 31.42 - 1,372.97. Worst -> Max. The number and size of the installments will depend on the contract sign.\n",
    "- Installment (Cuota): The monthly payment owed by the borrower if the loan originates (El pago mensual adeudado por el prestatario si se origina el prstamo.)\n",
    "\n",
    "- 'total_pymnt': 0 - 41,913.62. Will obviously incorporate all parameters mentioned above and will certainly be the largest positive value of all in nominal terms.\n",
    "- Total payment: Payments received to date for total amount funded (Pagos recibidos hasta la fecha por el monto total financiado)\n",
    "\n",
    "- 'funded_amnt': 1,000 - 35,000. Worst -> Min. Is the only col for which we want to set the filler values equal to the minimum.\n",
    "- Funded amount (Monto financiado): The total amount committed to that loan at that point in time. (El monto total comprometido para ese prstamo en ese momento.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "because they are assuming the worst case scenario\n",
    "\n",
    "for funded amount = the amount of money that the person provided to pay his loan, so if you only paid minimum amount, that means you still have  a lot more to pay and so it's considered bad scenario to have a minimum value.\n",
    "\n",
    "the others use maximum cause it again represents  the worst scenario, loan amount for example, for the bank,it's better to have someone who only took 10k insted of having someone who took 200k. the 200k person is more likely to default than the other one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt'], dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    35000.  ,       13.33,     1184.86,     9452.96],\n",
       "       [57693261.  ,    30000.  ,    30000.  , 68616520.  ,      938.57,     4679.7 ],\n",
       "       [59432726.  ,    15000.  ,    15000.  , 68616520.  ,      494.86,     1969.83],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,    10000.  , 68616520.  , 68616520.  ,     2185.64],\n",
       "       [46154151.  , 68616520.  ,    10000.  ,       16.55,      354.3 ,     3199.4 ],\n",
       "       [66055249.  ,    10000.  ,    10000.  , 68616520.  ,      309.97,      301.9 ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "68616520.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[  373332.  ,         nan,     1000.  ,         nan,     1000.  ,         nan,        6.  ,\n",
       "              31.42,         nan,         nan,         nan,         nan,         nan,        0.  ],\n",
       "       [54015809.19,         nan,    15273.46,         nan,    15311.04,         nan,       16.62,\n",
       "             440.92,         nan,         nan,         nan,         nan,         nan,     3143.85],\n",
       "       [68616519.  ,         nan,    35000.  ,         nan,    35000.  ,         nan,       28.99,\n",
       "            1372.97,         nan,         nan,         nan,         nan,         nan,    41913.62]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp_fill: 68,616,520.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Only Numeric orig_stats:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[  373332.  ,     1000.  ,     1000.  ,        6.  ,       31.42,        0.  ],\n",
       "       [54015809.19,    15273.46,    15311.04,       16.62,      440.92,     3143.85],\n",
       "       [68616519.  ,    35000.  ,    35000.  ,       28.99,     1372.97,    41913.62]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 0. Let's look numeric header and data and old calcs.\n",
    "display(header_num, data_num)\n",
    "display(temp_fill, orig_stats)\n",
    "print('temp_fill:', show_thseps(temp_fill))\n",
    "display('Only Numeric orig_stats:', orig_stats[:,cols_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Check that 'id' won't have missings (temp_fill)\n",
    "display(np.argwhere(header_num == 'id'))\n",
    "display(np.where(data_num[:,0] == temp_fill))\n",
    "# display(data_num[:,0] == temp_fill)\n",
    "# display((data_num[:,0] == temp_fill).sum())\n",
    "# display(np.sum(data_num[:,0] == temp_fill))\n",
    "display(np.isin(data_num[:,0], temp_fill))\n",
    "# display(np.isin(temp_fill, data_num[:,0]))\n",
    "display(np.isin(data_num[:,0], temp_fill).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt'], dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[2]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[4]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  4,  6,  7, 13], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[  373332.  ,     1000.  ,     1000.  ,        6.  ,       31.42,        0.  ],\n",
       "       [54015809.19,    15273.46,    15311.04,       16.62,      440.92,     3143.85],\n",
       "       [68616519.  ,    35000.  ,    35000.  ,       28.99,     1372.97,    41913.62]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1000.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1000.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. Replace temp_fill for min in 'funded_amnt'\n",
    "display(header_num)\n",
    "display(np.argwhere(header_num == 'funded_amnt'))\n",
    "display(np.argwhere(header_full == 'funded_amnt'))\n",
    "display(cols_num)\n",
    "display(orig_stats[:,cols_num])\n",
    "display(orig_stats[0, cols_num[2]])\n",
    "display(np.isin(data_num[:,2], temp_fill).sum())\n",
    "\n",
    "# np.min(np.where(data_num[:,2] == temp_fill,\n",
    "#                 orig_stats[0, cols_num[2]],\n",
    "#                 data_num[:,2]))\n",
    "\n",
    "data_num[:,2] = np.where(data_num[:,2] == temp_fill,\n",
    "                         orig_stats[0, cols_num[2]],\n",
    "                         data_num[:,2])\n",
    "\n",
    "display(np.min(data_num[:,2]))\n",
    "display(np.isin(data_num[:,2], temp_fill).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt'], dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  4,  6,  7, 13], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    35000.  ,       13.33,     1184.86,     9452.96],\n",
       "       [57693261.  ,    30000.  ,    30000.  ,       28.99,      938.57,     4679.7 ],\n",
       "       [59432726.  ,    15000.  ,    15000.  ,       28.99,      494.86,     1969.83],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,    10000.  ,       28.99,     1372.97,     2185.64],\n",
       "       [46154151.  ,    35000.  ,    10000.  ,       16.55,      354.3 ,     3199.4 ],\n",
       "       [66055249.  ,    10000.  ,    10000.  ,       28.99,      309.97,      301.9 ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "68616519.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "68616520.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68,616,519.0 68,616,520.0\n",
      "temp_fill - np.max(data_num): 1.0\n"
     ]
    }
   ],
   "source": [
    "# 3. Replace temp_fill for max in others num columns\n",
    "display(header_num)\n",
    "display(cols_num)\n",
    "\n",
    "# ix[1]='loan_amnt'; ix[3]='int_rate'; ix[4]=...\n",
    "for i in (1,3,4,5):\n",
    "    data_num[:,i] = np.where(data_num[:,i] == temp_fill,\n",
    "                             orig_stats[2, cols_num[i]],\n",
    "                             data_num[:,i])\n",
    "    \n",
    "display(data_num)\n",
    "display(np.max(data_num), temp_fill)\n",
    "print(show_thseps(np.max(data_num)), show_thseps(temp_fill))\n",
    "print('temp_fill - np.max(data_num):', temp_fill - np.max(data_num))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Manipulating Numeric Data: Currency Change - The Exchange Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- European office and USA BANK: we must keep all records in EUR as well as USD \n",
    "- To convert USD to EU we need the exchange rate between the two currencies at the time of each loan application.\n",
    "- issue_date were just months rather than specific dates. \n",
    "- EUR-USD.csv: contains the avg monthly exchange rate for 2015\n",
    "- Open, High, Low, Close, Volume columns. Close for us -> Adjusted closing prices.\n",
    "- In analysis, we often prefer to use the adjusted closing price.\n",
    "- We're no using a constant (unique) exchange rate (actually wue have one for each month), so we'll create a new col to store the exchange rates for each account (link with issue_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Let's see the content of EUR-USD.csv\n",
    "eur_usd_full = np.genfromtxt('9_EUR-USD.csv',\n",
    "                             delimiter=',',\n",
    "                             dtype=str,\n",
    "                             autostrip=True)\n",
    "\n",
    "# eur_usd_full <- Only care 'Close column'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.13, 1.12, 1.08, 1.11, 1.1 , 1.12, 1.09, 1.13, 1.13, 1.1 , 1.06, 1.09])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' eur_usd: | shape: (12,) | ndim: 1 | size: 12 | dtype: float64 '"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Import the data we really care of EUR-USD.csv (Close, col[3])\n",
    "eur_usd = np.genfromtxt('9_EUR-USD.csv',\n",
    "                        delimiter=',',\n",
    "                        autostrip=True,\n",
    "                        usecols=3,\n",
    "                        skip_header=1)\n",
    "display(eur_usd)\n",
    "show_attr('eur_usd')    # 12 vals, one for e/month (1-12) Ixs 0-11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_months', 'sub_grade', 'verification_status',\n",
       "       'state_address'], dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 5,  0,  9, ...,  6,  4, 12])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([1.1 , 1.11, 1.13, ..., 1.12, 1.11, 1.09])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' exch_rate: | shape: (10000,) | ndim: 1 | size: 10000 | dtype: float64 '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. Create exchange rate col (1st doing equal to issue_date)\n",
    "display(header_str)\n",
    "display(np.argwhere(header_str == 'issue_date'))\n",
    "display(exch_rate := data_str[:,0])\n",
    "\n",
    "# For e/account set the exch_rate depending on issue_date\n",
    "for i in range(1,13):     # for e/month 1-12\n",
    "    exch_rate = np.where(exch_rate == i, eur_usd[i - 1], exch_rate)\n",
    "\n",
    "# For cases val 0, missing vals in issue_date use annual mean\n",
    "exch_rate = np.where(exch_rate == 0, np.mean(eur_usd), exch_rate)\n",
    "\n",
    "display(exch_rate, show_attr('exch_rate'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    35000.  ,       13.33,     1184.86,     9452.96],\n",
       "       [57693261.  ,    30000.  ,    30000.  ,       28.99,      938.57,     4679.7 ],\n",
       "       [59432726.  ,    15000.  ,    15000.  ,       28.99,      494.86,     1969.83],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,    10000.  ,       28.99,     1372.97,     2185.64],\n",
       "       [46154151.  ,    35000.  ,    10000.  ,       16.55,      354.3 ,     3199.4 ],\n",
       "       [66055249.  ,    10000.  ,    10000.  ,       28.99,      309.97,      301.9 ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' data_num: | shape: (10000, 6) | ndim: 2 | size: 60000 | dtype: float64 '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[1.1 ],\n",
       "       [1.11],\n",
       "       [1.13],\n",
       "       ...,\n",
       "       [1.12],\n",
       "       [1.11],\n",
       "       [1.09]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' exch_rate: | shape: (10000, 1) | ndim: 2 | size: 10000 | dtype: float64 '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    35000.  , ...,     1184.86,     9452.96,        1.1 ],\n",
       "       [57693261.  ,    30000.  ,    30000.  , ...,      938.57,     4679.7 ,        1.11],\n",
       "       [59432726.  ,    15000.  ,    15000.  , ...,      494.86,     1969.83,        1.13],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,    10000.  , ...,     1372.97,     2185.64,        1.12],\n",
       "       [46154151.  ,    35000.  ,    10000.  , ...,      354.3 ,     3199.4 ,        1.11],\n",
       "       [66055249.  ,    10000.  ,    10000.  , ...,      309.97,      301.9 ,        1.09]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' data_num: | shape: (10000, 7) | ndim: 2 | size: 70000 | dtype: float64 '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. Add this col to the dataset (hstack)\n",
    "display(data_num, show_attr('data_num'))\n",
    "\n",
    "exch_rate = exch_rate.reshape(10000,1)\n",
    "display(exch_rate, show_attr('exch_rate'))\n",
    "\n",
    "data_num = np.hstack((data_num, exch_rate))\n",
    "display(data_num, show_attr('data_num'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt'], dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' header_num: | shape: (6,) | ndim: 1 | size: 6 | dtype: <U19 '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt', 'exchange_rate'],\n",
       "      dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' header_num: | shape: (7,) | ndim: 1 | size: 7 | dtype: <U19 '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4. Add a value to header_num (Since we add a col to data_num) - concatenate()\n",
    "display(header_num, show_attr('header_num'))\n",
    "header_num = np.concatenate((header_num, np.array(['exchange_rate'])))\n",
    "display(header_num, show_attr('header_num'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Manipulating Numeric Data: Currency Change - From USD to EUR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We'll create 3 new cols with the values in EUR\n",
    "- Also we'll accommodate thats new cols aside the corresponding ones in USD.\n",
    "- We'll rename de cols with _EUR the new ones and _USD the olds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converson from USD to EUR\n",
    "- We have the exchange EUR-USD rate, thats means:\n",
    "- EUR / USD = rate in the file => __USD = EUR / rate__ (USD expressed in EUR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt', 'exchange_rate'],\n",
       "      dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' header_num: | shape: (7,) | ndim: 1 | size: 7 | dtype: <U19 '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array(['exchange_rate', 'funded_amnt', 'id', 'installment', 'int_rate', 'loan_amnt', 'total_pymnt'],\n",
       "       dtype='<U19'),\n",
       " array([6, 2, 0, 4, 3, 1, 5], dtype=int64))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['loan_amnt', 'funded_amnt', 'installment', 'total_pymnt'], dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[35000.  , 35000.  ,  1184.86,  9452.96],\n",
       "       [30000.  , 30000.  ,   938.57,  4679.7 ],\n",
       "       [15000.  , 15000.  ,   494.86,  1969.83],\n",
       "       ...,\n",
       "       [10000.  , 10000.  ,  1372.97,  2185.64],\n",
       "       [35000.  , 10000.  ,   354.3 ,  3199.4 ],\n",
       "       [10000.  , 10000.  ,   309.97,   301.9 ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' data_num[:,cols_usd]: | shape: (10000, 4) | ndim: 2 | size: 40000 | dtype: float64 '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 0. Let's see which cols in headers (num because they have amnt in usd)\n",
    "display(header_num, show_attr('header_num'))\n",
    "\n",
    "# USD cols: loan_amnt, founded_amnt, installment, total_pymnt -> cols_usd\n",
    "display(np.unique(header_num, return_index=True))\n",
    "cols_usd = np.array([1,2,4,5])            # usd-cols Ixs\n",
    "display(header_num[cols_usd])\n",
    "\n",
    "# Data cols we are interested:\n",
    "display(data_num[:,cols_usd], show_attr('data_num[:,cols_usd]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.1 , 1.11, 1.13, ..., 1.12, 1.11, 1.09])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' data_num[:,6]: | shape: (10000,) | ndim: 1 | size: 10000 | dtype: float64 '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    35000.  , ...,    31933.3 ,     1081.04,     8624.69],\n",
       "       [57693261.  ,    30000.  ,    30000.  , ...,    27132.46,      848.86,     4232.39],\n",
       "       [59432726.  ,    15000.  ,    15000.  , ...,    13326.3 ,      439.64,     1750.04],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,    10000.  , ...,     8910.3 ,     1223.36,     1947.47],\n",
       "       [46154151.  ,    35000.  ,    10000.  , ...,     8997.4 ,      318.78,     2878.63],\n",
       "       [66055249.  ,    10000.  ,    10000.  , ...,     9145.8 ,      283.49,      276.11]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' data_num: | shape: (10000, 11) | ndim: 2 | size: 110000 | dtype: float64 '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Create the new data_num cols that will have the values in EUR\n",
    "display(data_num[:,6], show_attr('data_num[:,6]'))    # exchange rates col\n",
    "\n",
    "for ix in cols_usd:     # for e/usd original col \n",
    "    data_num = np.hstack((data_num,\n",
    "                          np.reshape(data_num[:,ix] / data_num[:,6], (10000,1))))\n",
    "    \n",
    "display(data_num, show_attr('data_num'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt', 'exchange_rate'],\n",
       "      dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' header_num: | shape: (7,) | ndim: 1 | size: 7 | dtype: <U19 '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['loan_amnt_EUR', 'funded_amnt_EUR', 'installment_EUR', 'total_pymnt_EUR'], dtype='<U15')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' header_eur: | shape: (4,) | ndim: 1 | size: 4 | dtype: <U15 '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt', 'exchange_rate',\n",
       "       'loan_amnt_EUR', 'funded_amnt_EUR', 'installment_EUR', 'total_pymnt_EUR'], dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' header_num: | shape: (11,) | ndim: 1 | size: 11 | dtype: <U19 '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. Modify the header to contain the new columns:\n",
    "# same name as originals + _EUR, ex. header_col[8] = header_col[1] + _EUR\n",
    "display(header_num, show_attr('header_num'))\n",
    "header_eur = np.array([col_nm + '_EUR' for col_nm in header_num[cols_usd]])\n",
    "display(header_eur, show_attr('header_eur'))\n",
    "# header_num = np.hstack((header_num, header_eur))      # JM Same result\n",
    "header_num = np.concatenate((header_num, header_eur))\n",
    "display(header_num, show_attr('header_num'))\n",
    "\n",
    "# for ix in cols_usd:     # JM way 1\n",
    "#     header_num = np.hstack((header_num,\n",
    "#                             np.array(header_num[ix] + '_EUR')))\n",
    "\n",
    "# for ix in cols_usd:     # JM way 2\n",
    "#     header_num = np.concatenate((header_num,\n",
    "#                                  np.array([header_num[ix] + '_EUR'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['loan_amnt', 'funded_amnt', 'installment', 'total_pymnt'], dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt_USD', 'funded_amnt_USD', 'int_rate', 'installment_USD', 'total_pymnt_USD',\n",
       "       'exchange_rate', 'loan_amnt_EUR', 'funded_amnt_EUR', 'installment_EUR', 'total_pymnt_EUR'],\n",
       "      dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. Rename the cols names that te amnt in usd sey _USD\n",
    "display(header_num[cols_usd])\n",
    "header_num[cols_usd] = np.array(\n",
    "    [usd_nm + '_USD' for usd_nm in header_num[cols_usd]])\n",
    "display(header_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt_USD', 'funded_amnt_USD', 'int_rate', 'installment_USD', 'total_pymnt_USD',\n",
       "       'exchange_rate', 'loan_amnt_EUR', 'funded_amnt_EUR', 'installment_EUR', 'total_pymnt_EUR'],\n",
       "      dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt_USD', 'loan_amnt_EUR', 'funded_amnt_USD', 'funded_amnt_EUR', 'int_rate',\n",
       "       'installment_USD', 'installment_EUR', 'total_pymnt_USD', 'total_pymnt_EUR', 'exchange_rate'],\n",
       "      dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' header_num: | shape: (11,) | ndim: 1 | size: 11 | dtype: <U19 '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    31933.3 , ...,     9452.96,     8624.69,        1.1 ],\n",
       "       [57693261.  ,    30000.  ,    27132.46, ...,     4679.7 ,     4232.39,        1.11],\n",
       "       [59432726.  ,    15000.  ,    13326.3 , ...,     1969.83,     1750.04,        1.13],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,     8910.3 , ...,     2185.64,     1947.47,        1.12],\n",
       "       [46154151.  ,    35000.  ,    31490.9 , ...,     3199.4 ,     2878.63,        1.11],\n",
       "       [66055249.  ,    10000.  ,     9145.8 , ...,      301.9 ,      276.11,        1.09]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' data_num: | shape: (10000, 11) | ndim: 2 | size: 110000 | dtype: float64 '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4. Rearrange the cols position to have side by side USD follow by EUR (header & data)\n",
    "display(header_num)\n",
    "display(np.argwhere(header_num).squeeze())\n",
    "cols_ixs_order = [0, 1, 7, 2, 8, 3, 4, 9, 5, 10, 6]\n",
    "header_num = header_num[cols_ixs_order]\n",
    "display(header_num, show_attr('header_num'))\n",
    "\n",
    "data_num = data_num[:,cols_ixs_order]\n",
    "display(data_num, show_attr('data_num'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric data preprocess summary:\n",
    "10. Appropriately filled out any missing values\n",
    "11. Added exchange rates for e/applicant (account)\n",
    "12. Created EUR version of the 4 monetary values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt_USD', 'loan_amnt_EUR', 'funded_amnt_USD', 'funded_amnt_EUR', 'int_rate',\n",
       "       'installment_USD', 'installment_EUR', 'total_pymnt_USD', 'total_pymnt_EUR', 'exchange_rate'],\n",
       "      dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[5]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([13.33, 28.99, 28.99, ..., 28.99, 16.55, 28.99])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' data_num[:,5]: | shape: (10000,) | ndim: 1 | size: 10000 | dtype: float64 '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.13, 0.29, 0.29, ..., 0.29, 0.17, 0.29])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' data_num[:,5]: | shape: (10000,) | ndim: 1 | size: 10000 | dtype: float64 '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 0.06 - Max: 0.2899\n"
     ]
    }
   ],
   "source": [
    "# 5. 'int_rate' col: better to have values between 0 and 1\n",
    "display(header_num)\n",
    "display(np.argwhere(header_num == 'int_rate'))\n",
    "display(data_num[:,5], show_attr('data_num[:,5]'))\n",
    "data_num[:,5] = data_num[:,5] / 100\n",
    "display(data_num[:,5], show_attr('data_num[:,5]'))\n",
    "# np.unique(data_num[:,5])\n",
    "print(f'Min: {np.min(data_num[:,5])} - Max: {np.max(data_num[:,5])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['header', 'data']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt_USD', 'loan_amnt_EUR', 'funded_amnt_USD', 'funded_amnt_EUR', 'int_rate',\n",
       "       'installment_USD', 'installment_EUR', 'total_pymnt_USD', 'total_pymnt_EUR', 'exchange_rate'],\n",
       "      dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\" chkpt_num['header']: | shape: (11,) | ndim: 1 | size: 11 | dtype: <U19 \""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    31933.3 , ...,     9452.96,     8624.69,        1.1 ],\n",
       "       [57693261.  ,    30000.  ,    27132.46, ...,     4679.7 ,     4232.39,        1.11],\n",
       "       [59432726.  ,    15000.  ,    13326.3 , ...,     1969.83,     1750.04,        1.13],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,     8910.3 , ...,     2185.64,     1947.47,        1.12],\n",
       "       [46154151.  ,    35000.  ,    31490.9 , ...,     3199.4 ,     2878.63,        1.11],\n",
       "       [66055249.  ,    10000.  ,     9145.8 , ...,      301.9 ,      276.11,        1.09]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\" chkpt_num['data']: | shape: (10000, 11) | ndim: 2 | size: 110000 | dtype: float64 \""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 6 Create checkpoing of numeric data preprocess\n",
    "chkpt_num = chkpt('chkpt-num', header_num, data_num)\n",
    "display(chkpt_num.files)\n",
    "\n",
    "display(chkpt_num['header'], show_attr(\"chkpt_num['header']\"))\n",
    "display(chkpt_num['data'], show_attr(\"chkpt_num['data']\"))\n",
    "display(np.array_equal(chkpt_num['header'], header_num))\n",
    "display(np.array_equal(chkpt_num['data'], data_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Completing the Dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finalize de dataset. Put toeghether all the parts and save te preprocessed data in a .csv file\n",
    "- At the begining we split the orig dtset in two num and str (also header and data of both).\n",
    "- Now we have these parts: header_str, data_str, header_num, data_num\n",
    "- We construct one of all and use the checkpoints files cause they are safer if we modify de arrays latter to save the checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_months', 'sub_grade', 'verification_status',\n",
       "       'state_address'], dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\" chkpt_str['header']: | shape: (6,) | ndim: 1 | size: 6 | dtype: <U19 \""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 5,  1, 36, 13,  1,  1],\n",
       "       [ 0,  1, 36,  5,  1,  4],\n",
       "       [ 9,  1, 36, 10,  1,  4],\n",
       "       ...,\n",
       "       [ 6,  1, 36,  5,  1,  1],\n",
       "       [ 4,  1, 36, 17,  1,  3],\n",
       "       [12,  1, 36,  4,  0,  3]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\" chkpt_str['data']: | shape: (10000, 6) | ndim: 2 | size: 60000 | dtype: int32 \""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt_USD', 'loan_amnt_EUR', 'funded_amnt_USD', 'funded_amnt_EUR', 'int_rate',\n",
       "       'installment_USD', 'installment_EUR', 'total_pymnt_USD', 'total_pymnt_EUR', 'exchange_rate'],\n",
       "      dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\" chkpt_num['header']: | shape: (11,) | ndim: 1 | size: 11 | dtype: <U19 \""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    31933.3 , ...,     9452.96,     8624.69,        1.1 ],\n",
       "       [57693261.  ,    30000.  ,    27132.46, ...,     4679.7 ,     4232.39,        1.11],\n",
       "       [59432726.  ,    15000.  ,    13326.3 , ...,     1969.83,     1750.04,        1.13],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,     8910.3 , ...,     2185.64,     1947.47,        1.12],\n",
       "       [46154151.  ,    35000.  ,    31490.9 , ...,     3199.4 ,     2878.63,        1.11],\n",
       "       [66055249.  ,    10000.  ,     9145.8 , ...,      301.9 ,      276.11,        1.09]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\" chkpt_num['data']: | shape: (10000, 11) | ndim: 2 | size: 110000 | dtype: float64 \""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 0. lets take a look\n",
    "\n",
    "for part in ('header', 'data'):\n",
    "    display(chkpt_str[part], show_attr(f\"chkpt_str['{part}']\"))\n",
    "for part in ('header', 'data'):   \n",
    "    display(chkpt_num[part], show_attr(f\"chkpt_num['{part}']\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    31933.3 , ...,       13.  ,        1.  ,        1.  ],\n",
       "       [57693261.  ,    30000.  ,    27132.46, ...,        5.  ,        1.  ,        4.  ],\n",
       "       [59432726.  ,    15000.  ,    13326.3 , ...,       10.  ,        1.  ,        4.  ],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,     8910.3 , ...,        5.  ,        1.  ,        1.  ],\n",
       "       [46154151.  ,    35000.  ,    31490.9 , ...,       17.  ,        1.  ,        3.  ],\n",
       "       [66055249.  ,    10000.  ,     9145.8 , ...,        4.  ,        0.  ,        3.  ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' data: | shape: (10000, 17) | ndim: 2 | size: 170000 | dtype: float64 '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Let's hstack datas (same dim and same num of rows) num + str\n",
    "data = np.hstack((chkpt_num['data'], chkpt_str['data']))\n",
    "display(data, show_attr('data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt_USD', 'loan_amnt_EUR', 'funded_amnt_USD', 'funded_amnt_EUR', 'int_rate',\n",
       "       'installment_USD', 'installment_EUR', 'total_pymnt_USD', 'total_pymnt_EUR', 'exchange_rate',\n",
       "       'issue_date', 'loan_status', 'term_months', 'sub_grade', 'verification_status',\n",
       "       'state_address'], dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' header_jm: | shape: (17,) | ndim: 1 | size: 17 | dtype: <U19 '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt_USD', 'loan_amnt_EUR', 'funded_amnt_USD', 'funded_amnt_EUR', 'int_rate',\n",
       "       'installment_USD', 'installment_EUR', 'total_pymnt_USD', 'total_pymnt_EUR', 'exchange_rate',\n",
       "       'issue_date', 'loan_status', 'term_months', 'sub_grade', 'verification_status',\n",
       "       'state_address'], dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' header: | shape: (17,) | ndim: 1 | size: 17 | dtype: <U19 '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. Let's concatenate headers (jm-hstack also) num + str\n",
    "header_jm = np.hstack((chkpt_num['header'], chkpt_str['header']))\n",
    "display(header_jm, show_attr('header_jm'))\n",
    "\n",
    "header = np.concatenate((chkpt_num['header'], chkpt_str['header']))\n",
    "display(header, show_attr('header'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([48010226., 57693261., 59432726., ..., 50415990., 46154151., 66055249.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([  373332.,   575239.,   707689., ..., 68614880., 68615915., 68616519.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([2086, 4812, 2353, ..., 4935, 9388, 8415], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([  373332.,   575239.,   707689., ..., 68614880., 68615915., 68616519.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 9997, 9998, 9999], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[  373332.  ,     9950.  ,     9038.08, ...,       21.  ,        0.  ,        1.  ],\n",
       "       [  575239.  ,    12000.  ,    10900.2 , ...,       25.  ,        1.  ,        2.  ],\n",
       "       [  707689.  ,    10000.  ,     8924.3 , ...,       13.  ,        1.  ,        0.  ],\n",
       "       ...,\n",
       "       [68614880.  ,     5600.  ,     5121.65, ...,        8.  ,        1.  ,        1.  ],\n",
       "       [68615915.  ,     4000.  ,     3658.32, ...,       10.  ,        1.  ,        2.  ],\n",
       "       [68616519.  ,    21600.  ,    19754.93, ...,        3.  ,        0.  ,        2.  ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' data: | shape: (10000, 17) | ndim: 2 | size: 170000 | dtype: float64 '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. Sort the num data by id column\n",
    "display(np.argwhere(header == 'id'))\n",
    "display(data[:,0], np.sort(data[:,0]))\n",
    "display(col0_ixs := np.argsort(data[:,0]))\n",
    "\n",
    "# Rearrange data sorted by id (col[0])\n",
    "data = data[np.argsort(data[:,0]), :]   # =data[np.argsort(data[:,0])]\n",
    "display(data[:,0], np.argsort(data[:,0]))\n",
    "display(data, show_attr('data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['id', 'loan_amnt_USD', 'loan_amnt_EUR', ..., 'sub_grade', 'verification_status',\n",
       "        'state_address'],\n",
       "       ['373332.0', '9950.0', '9038.082814338286', ..., '21.0', '0.0', '1.0'],\n",
       "       ['575239.0', '12000.0', '10900.20037910145', ..., '25.0', '1.0', '2.0'],\n",
       "       ...,\n",
       "       ['68614880.0', '5600.0', '5121.647851612413', ..., '8.0', '1.0', '1.0'],\n",
       "       ['68615915.0', '4000.0', '3658.319894008867', ..., '10.0', '1.0', '2.0'],\n",
       "       ['68616519.0', '21600.0', '19754.927427647883', ..., '3.0', '0.0', '2.0']], dtype='<U32')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' data_prepro: | shape: (10001, 17) | ndim: 2 | size: 170017 | dtype: <U32 '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4. Let's vstack headers and data\n",
    "data_prepro= np.vstack((header, data))\n",
    "display(data_prepro, show_attr('data_prepro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Save the .csv file\n",
    "np.savetxt('loan-data-preprocessed.csv',\n",
    "           data_prepro,\n",
    "           delimiter=',',\n",
    "           fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Setting Up: Introduction to the Practical Example\n",
    "- Setting Up: Importing the Data Set\n",
    "- Setting Up: Checking for Incomplete Data\n",
    "- Setting Up: Splitting the Dataset\n",
    "- Setting Up: Creating Checkpoints\n",
    "- Manipulating Text Data: Issue Date\n",
    "- Manipulating Text Data: Loan Status and Term\n",
    "- Manipulating Text Data: Grade and Sub Grade\n",
    "- Manipulating Text Data: Verification Status & URL\n",
    "- Manipulating Text Data: State Address\n",
    "- Manipulating Text Data: Converting Strings and Creating a Checkpoint\n",
    "- Manipulating Numeric Data: Substitute Filler Values\n",
    "- Manipulating Numeric Data: Currency Change - The Exchange Rate\n",
    "- Manipulating Numeric Data: Currency Change - From USD to EUR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Welcome to the documentation.\n",
    "\n",
    "## Installation\n",
    "\n",
    "To install the package, follow these steps:\n",
    "\n",
    "1. Download the package.\n",
    "2. Run the installer.\n",
    "\n",
    "Go to Installation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JM Walrus Operator Discover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['id', 'issue_d', 'loan_amnt', 'loan_status', 'funded_amnt', 'term', 'int_rate',\n",
       "       'installment', 'grade', 'sub_grade', 'verification_status', 'url', 'addr_state',\n",
       "       'total_pymnt'], dtype='<U69')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'term_months'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1, 3, 5, 7]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Walrus Operator NOT working in all cases - problem with Indexing\n",
    "display(c := 5 + 4)\n",
    "# display(data_str[:,2] := np.chararray.strip(data_str[:,2], ' months')) # SyntaxError\n",
    "display(header_full_jm)\n",
    "# display(header_full_jm[2] := 'term_months')\n",
    "display(a_variable := 'term_months')\n",
    "display(lst := [i for i in range(9) if i % 2 != 0])\n",
    "# display(lst[1] := 0)    # SyntaxError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Internal links\n",
    "\n",
    "# For internal (within the same notebook) links use this code:\n",
    "# [section title](#section-title)\n",
    "# For the text in the parentheses, replace spaces and special characters with a hyphen.\n",
    "\n",
    "# Alternatively, you can add an ID for a section right above the section title.\n",
    "# Use this code: <a id=\"section_ID\"></a>\n",
    "\n",
    "# Make sure that the section_ID is unique within the notebook.\n",
    "# Use this code: [section title](#section_ID)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
