{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Data Preprocessing with NumPy\n",
    "- Practice Exam #1\n",
    "- Practice Exam #2\n",
    "- Practice Exam #3\n",
    "- Practice Exam #4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[## PE#1 - Indexing, Assigning, np.squeeze()](#pe1---indexing-assigning-npsqueeze)\n",
    "\n",
    "[## PE#2 - Generating Data](#pe2---generating-data)\n",
    "\n",
    "[## PE#3 - Read and Save Data + Statistics](#pe3---read-and-save-data--statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import Generator as gen  \n",
    "from numpy.random import PCG64 as pcg   \n",
    "\n",
    "np.__version__\n",
    "np.set_printoptions(suppress=True, linewidth=100, precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function show_attr def\n",
    "\n",
    "def show_attr(arrnm: str) -> str:\n",
    "    ''' Show numpy ndarray principal attributes\n",
    "    \n",
    "    arrnm: array name. Must exist en the main program body\n",
    "    --> CAN NOT be call inside other function\n",
    "    '''\n",
    "    \n",
    "    if not isinstance(arrnm, str):\n",
    "          return '-> show_attr() >> ERROR: argument must be an string!'\n",
    "    \n",
    "    strout = f' {arrnm}: '\n",
    "    for attr in ('shape', 'ndim', 'size', 'dtype'):     #, 'itemsize'):\n",
    "            arrnm_attr = arrnm + '.' + attr\n",
    "            strout += f'| {attr}: {eval(arrnm_attr)} '\n",
    "\n",
    "    return strout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PE#1 - Indexing, Assigning, np.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PE#2 - Generating Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. __numpy.empyt(shape=, dtype=)__\n",
    "   - .ones(); .zeros(), .full(fill_value)\n",
    "2. __ndarray.empy_like(arr, dtype=)__\n",
    "   - ones_like(); zeros_like(), full_like(fill_value)\n",
    "3. __form numpy.random import Generator as gen | PCG64 as pcg__\n",
    "   - PCG64 bit generator | rg = gen(pcg(seed=42)); rg.normal(size=(3,5))\n",
    "4. __random.Generator.integers(low, high=None, size=None, dtype=np.int64, endpoint=False)__ <- method\n",
    "   - .random(size=, dtype=, out=None); .choice(a, size=None, p=)\n",
    "5. __random.Generator.normal(loc=0.0, scale=1.0, size=None)__ <- method\n",
    "   - .poisson(lam=) ; .binomial(n, p); .logistic(loc=, scale=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 12,  45,   6],\n",
       "       [ 55,  34,  -4],\n",
       "       [ -6, -12,  90]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[-1, -1, -1],\n",
       "       [-1, -1, -1],\n",
       "       [-1, -1, -1]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[-1, -1, -1],\n",
       "       [-1, -1, -1],\n",
       "       [-1, -1, -1]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. ones_like - full_like\n",
    "# 1. Knowing A create 3x3 arr which e/entry = -1\n",
    "A = np.array([[12,45,6], [55,34,-4], [-6,-12,90]])\n",
    "display(A)\n",
    "r1 = np.full_like(A, fill_value=-1)\n",
    "r2 = -np.ones_like(A)\n",
    "display(r1, r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n",
       "       23, 24])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. np.arange(start, stop, step, dtype)\n",
    "# f = np.arange(start=25)     # TypeError: arange() requires stop to be specified.\n",
    "f = np.arange(25)\n",
    "g = np.arange(30, step=1.5, dtype=np.int32)\n",
    "display(f, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.91,  0.75, -0.03,  0.65, -0.65],\n",
       "       [-1.83,  1.68,  0.48, -2.07, -1.06],\n",
       "       [-0.62,  0.34,  1.33,  0.31, -0.43],\n",
       "       [ 0.47, -0.22,  0.18, -0.67, -1.21],\n",
       "       [ 1.28, -0.32,  0.12, -0.6 , -0.54]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.  rg.normal .integers .random\n",
    "# 3. generate a 5x5 arr, full of fixed vals drawn from a normal dist.\n",
    "rg = gen(pcg(seed=32))\n",
    "arr = rg.normal(size=(5,5))\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12, 3, 4, 10, -5, 9, 19, 21, 100, 89]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 89,   9,   3],\n",
       "       [ -5, 100,   3],\n",
       "       [ 89,  19,  10]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. rg.choice(p=) probability\n",
    "# 4. twice more likely to draw nums from t3 than t1, and 4 times more from t2 than t1\n",
    "t1 = (12, 3, 4, 10)\n",
    "t2 = (-5, 9)\n",
    "t3 = (19, 21, 100, 89)\n",
    "\n",
    "m = list(t1 + t2 + t3)\n",
    "display(m)\n",
    "\n",
    "rg = gen(pcg(seed=64))\n",
    "arr = rg.choice(m,\n",
    "                p=[0.05, 0.05, 0.05, 0.05, 0.2, 0.2, 0.1, 0.1, 0.1, 0.1],\n",
    "                size=(3,3))\n",
    "\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.666666666666668"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Binomial distr\n",
    "# 5. coin w/probability of heads 0.3 and 80 tosses, (seed=60)\n",
    "rg = gen(pcg(seed=60))\n",
    "arr = rg.binomial(n=80, p=0.3, size=(3,3))\n",
    "np.mean(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.04153699695336"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. rg.'distributions' \n",
    "# 6. c1, c2, c3: norma, exponential, logistic\n",
    "rg = gen(pcg(seed=365))\n",
    "c1 = rg.normal(loc=3, scale=2, size=(500))\n",
    "c2 = rg.exponential(scale=5, size=(500))\n",
    "c3 = rg.logistic(loc=10, scale=4, size=(500))\n",
    "\n",
    "t = np.array([c1, c2, c3]).T\n",
    "np.max(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XTRA\n",
    "rg = gen(pcg(seed=365))\n",
    "\n",
    "inte = rg.integers(low=-20, high=99, size=(4,6))\n",
    "rand = rg.random(size=(3,5))\n",
    "# display(inte, rand)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PE#3 - Read and Save Data + Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Importing and Saving Data with NumPy\n",
    "1. __numpy.loadtxt(fname, delimiter=, usecols=, unpack=,...)__\n",
    "   - (fname, dtype='float', ...)\n",
    "2. __numpy.genfromtxt(fname, delimiter=, skip_header=, skip_footer=, filling_values=e, usecols=,  unpack=, ...)__\n",
    "   - (fname, dtype=<'float', ...)\n",
    "3. __numpy.save(file, arr, ...)__ - .npy file\n",
    "   - np.save() -> .npy file <- .load()\n",
    "4. __numpy.savez(file, *args, **kwds)__ - .npz file\n",
    "   - ('file', header=arr_h, data=arr_d)\n",
    "   - savez(file, x, y), names will be 'arr_0', 'arr_1', etc.\n",
    "5. __numpy.savetxt(fname, X, fmt='%s', delimiter=' ',...)__\n",
    "   - fname with extension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Statistics with NumPy\n",
    "1. __np.sort()__\n",
    "   - axis=None (flat) idem np.sort(np.reshape(X,))\n",
    "2. __np.min(axis=) - np.amin(axis=)__\n",
    "3. __np.max() - np.amax() .-| axis=__\n",
    "4. __np.minimun(), np.maximun()__\n",
    "   .reduce() .-| \n",
    "5. __np.median() .-| axis=__\n",
    "6. __numpy.ptp(a, axis=None, ...)__\n",
    "   (..., out=None, keepdims=<no value>)\n",
    "7. __np.percentile()__\n",
    "   - q=0-100, axis=\n",
    "8. __np.quantile()__\n",
    "   - q=0-1, axis=\n",
    "9.  __np.mean(axis=)__\n",
    "10. __np.average() .-| weights=, axis=__\n",
    "11. __numpy.std(a, axis=None, dtype=None,...)__\n",
    "   - (...,out=None, ddof=0, keepdims=<no value>, *, where=<no value>, mean=<no value>, correction=<no value>)\n",
    "13. __numpy.var(a, axis=None, dtype=None, ...)__\n",
    "   -(..., out=None, ddof=0, keepdims=<no value>, *, where=<no value>, mean=<no value>, correction=<no value>)\n",
    "14. __np.cov() .-| m, y=None, rowvar=True .-| cov(X,X)= var(X)__\n",
    "15. __np.corrcoef .-| x, y=None, rowvar=True__\n",
    "16. __np.histogram .-| a, bins=, range=__\n",
    "17. __np.histogram2d .-| x, y, bins=, range=__\n",
    "18. __np.histogramdd .-| sample, bins, range=__\n",
    "- NAN equiv funct. - np.nanvar() - np.nan... .-| jm -> np.histogram(A[~np.isnan(A)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. loadtxt() is faster than genfromtxt(), but breaks down if we feed it incomplete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1000.,    35.,   365., -2870., -2870.,  -350.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 1000.,    35.,   365., -2870., -2870.,  -350.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 1000.,    35.,   365., -2870., -2870.,  -350.])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Minimum in each separate colum\n",
    "txt = np.genfromtxt('Lending-Company-Numeric-Data.csv', delimiter=',')\n",
    "display(np.min(txt, axis=0))\n",
    "display(np.minimum.reduce(txt, axis=0))\n",
    "np.minimum.reduce(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.75"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Percentile - Quantile\n",
    "# 3. First 5 of 20 - One do 88% (entra al equipo?)\n",
    "r = np.array([[58,62,92,79,65], [91,66,72,74,84],\n",
    "              [38,81,23,45,89], [49,95,86,26,90]])\n",
    "percent_q = (20 - 5) / 20 * 100\n",
    "np.percentile(r, percent_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median: 177.0 - Percentil(50%): 177.0 - Quantil(0.5): 177.0\n"
     ]
    }
   ],
   "source": [
    "# 4. .median(a) = .percentile(a, q=50)\n",
    "heights = np.array([[158,162,175,179,188], [191,163,172,174,184],\n",
    "                    [182,181,163,155,179], [159,195,186,166,190]])\n",
    "\n",
    "m = np.median(heights)\n",
    "p = np.percentile(heights, q=50)\n",
    "q = np.quantile(heights, q=0.5)\n",
    "\n",
    "print(f'Median: {m} - Percentil(50%): {p} - Quantil(0.5): {q}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28.67, 33.67,  3.  , 25.33],\n",
       "       [33.67, 59.  ,  3.  , 40.33],\n",
       "       [ 3.  ,  3.  ,  1.67, -3.67],\n",
       "       [25.33, 40.33, -3.67, 55.33]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.  ,  0.82,  0.43,  0.64],\n",
       "       [ 0.82,  1.  ,  0.3 ,  0.71],\n",
       "       [ 0.43,  0.3 ,  1.  , -0.38],\n",
       "       [ 0.64,  0.71, -0.38,  1.  ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[28.67,  3.  ],\n",
       "       [ 3.  ,  1.67]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.  , -0.38],\n",
       "       [-0.38,  1.  ]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Covariance and Correlation - .cov(X,Y); .corrcoef(X,Y)\n",
    "# 5. .cov between r0 and r2 and .corrcoef between r2 an r3\n",
    "arr = np.array([[1,2,-4,9], [1,12,-3,12], [1,2,3,4], [5,6,-10,3]])\n",
    "display(np.cov(arr))\n",
    "display(np.corrcoef(arr))\n",
    "display(np.cov(arr[0], arr[2]))\n",
    "np.corrcoef(arr[2], arr[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  3,  3,  4,  4,  5,  7,  9,  9, 10, 11, 12, 12, 12, 15, 16, 17, 19, 21, 21, 22,\n",
       "       22, 28, 29, 30, 33, 34, 34, 35, 35, 37, 39, 39])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([6, 5, 2, 4, 7], dtype=int64), array([10., 16., 22., 28., 34., 40.]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([11,  6,  5,  2,  4,  7], dtype=int64),\n",
       " array([ 0, 10, 16, 22, 28, 34, 40]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 6. Histogram - Probability class' final exams\n",
    "# 6. 35 students - 40 Qs - c_q: correct questions\n",
    "# Grades: A(34-40); B(28-34); C(22-28); D(16-22); E(10-16); <10 re-take\n",
    "\n",
    "c_q = np.array([39,30,35,21,22,3,10,3,22,4,21,29,37,34,12,4,35,7,12,19,34,39,1,12,\n",
    "                11,28,2,17,3,16,9,33,5,15,9])\n",
    "display(np.sort(c_q))\n",
    "h1 = np.histogram(c_q, bins=5, range=(10,40))\n",
    "h2 = np.histogram(c_q, bins=[0,10,16,22,28,34,40])\n",
    "display(h1, h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PE#4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. __np.loadtxt('filenm', delimiter=, dtype=, usecols=)__\n",
    "   - fails with missing vals (NANs)\n",
    "2. __np.isnan(arr)__ {ufunc}\n",
    "   - np.isnan().sum()\n",
    "3. __np.genfromtxt('filenm', delimiter=, filling_values=tmp)__\n",
    "    - dtype=float, usecols=None, skip_header or footer=0\n",
    "4. __np.where(condition, True, False)__\n",
    "5. __np.reshape()__ <- inplace Flase>\n",
    "    - add dims artificially -> np.reshape(1,1,3,5) + method\n",
    "6. __np.delete(arr, ixs, axis=None)__ <- inplace False>\n",
    "    - 2-D arr axis=0 row, axis=1 cols | .delete(.delete( axis=1) axis=0) cols and rows\n",
    "7. __np.sort(arr, axis=1)__ <- inplace False>\n",
    "    - -np.sort(-arr) <- descending | arr.sort() <- inplace True!! | axis=-1 default (en 2D is = 1 rows)\n",
    "8. __np.argsort(arr, axis=-1)__ <- inplace False>\n",
    "    - .argsort() method idem <- inplacer False>\n",
    "9.  __np.argwhere(arr)__ {arr or condition}\n",
    "    - indices of non-zero elements of arr | argwhere(isnan(a))\n",
    "10.  __np.shuffle(arr)__ <-inplace True> NO axis= (only rows)\n",
    "     - Also .shuffle(arr, axis=0) Generator method <-inplace True> | 2-D array axis=0 shuffle rows, axis=1 shuffle cols.\n",
    "11. np.astype() | <- inplace False> idem the .astype() method\n",
    "12. np.chararray.strip(arr, 'str') <- inplacer False>\n",
    "13. np.stack(arr, axis=0) <- inplace False>\n",
    "    - stack add 1Dim | .stack() SAME shape, .vstack() and .hstack() NO  | .dstack() depth\n",
    "14. __np.concatenate((tup_arrs), axis=0)__ <-inplace False>\n",
    "    - axis=0 > .vstack; axis=1 > .hstack; axis=2 > dstack\n",
    "15. __np.unique(arr, return_index=False, return_counts=False)__\n",
    "    - return unique values, ascending sorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.__version__\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function show_attr\n",
    "\n",
    "def show_attr(arrnm: str) -> str:\n",
    "    strout = f' {arrnm}: '\n",
    "\n",
    "    for attr in ('shape', 'ndim', 'size', 'dtype'):     #, 'itemsize'):\n",
    "            arrnm_attr = arrnm + '.' + attr\n",
    "            strout += f'| {attr}: {eval(arrnm_attr)} '\n",
    "\n",
    "    return strout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dataU: | shape: (1043, 6) | ndim: 2 | size: 6258 | dtype: float64 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load NON-NAN data\n",
    "dataU = np.loadtxt('Lending-Company-Numeric-Data.csv',\n",
    "                  delimiter=',')\n",
    "print(show_attr('dataU'))\n",
    "np.isnan(dataU).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dataN: | shape: (1043, 6) | ndim: 2 | size: 6258 | dtype: float64 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "260"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read NAN data\n",
    "dataN = np.genfromtxt('Lending-Company-Numeric-Data-NAN.csv',\n",
    "                     delimiter=';')\n",
    "print(show_attr('dataN'))\n",
    "np.isnan(dataN).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Data_preprocessing_Numpy.csv not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[96], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# read exam data \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenfromtxt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mData_preprocessing_Numpy.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m;\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m                     \u001b[38;5;66;03m#  skip_header=1)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m display(data)\n",
      "File \u001b[1;32mc:\\Users\\jm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\npyio.py:1980\u001b[0m, in \u001b[0;36mgenfromtxt\u001b[1;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding, ndmin, like)\u001b[0m\n\u001b[0;32m   1978\u001b[0m     fname \u001b[38;5;241m=\u001b[39m os_fspath(fname)\n\u001b[0;32m   1979\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fname, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m-> 1980\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_datasource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1981\u001b[0m     fid_ctx \u001b[38;5;241m=\u001b[39m contextlib\u001b[38;5;241m.\u001b[39mclosing(fid)\n\u001b[0;32m   1982\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\_datasource.py:193\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03mOpen `path` with `mode` and return the file object.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    189\u001b[0m \n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    192\u001b[0m ds \u001b[38;5;241m=\u001b[39m DataSource(destpath)\n\u001b[1;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\_datasource.py:533\u001b[0m, in \u001b[0;36mDataSource.open\u001b[1;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _file_openers[ext](found, mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m    531\u001b[0m                               encoding\u001b[38;5;241m=\u001b[39mencoding, newline\u001b[38;5;241m=\u001b[39mnewline)\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 533\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Data_preprocessing_Numpy.csv not found."
     ]
    }
   ],
   "source": [
    "# read exam data \n",
    "data = np.genfromtxt('Data_preprocessing_Numpy.csv',\n",
    "                     delimiter=';')\n",
    "                    #  skip_header=1)\n",
    "\n",
    "display(data)\n",
    "print(show_attr('data'))\n",
    "print(np.isnan(data).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jm\\AppData\\Local\\Temp\\ipykernel_1480\\1500593355.py:2: RuntimeWarning: Mean of empty slice\n",
      "  np.nanmean(data, axis=0).round(2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([     nan,    47.5 ,   365.  ,  3495.16,  5073.5 , 18461.31])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q2\n",
    "np.nanmean(data, axis=0).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1850.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([-1850.  ,  -258.55,  -135.16,  2460.61,  3510.13, 15185.29])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q3\n",
    "# print('1stColMean:', np.nanmean(data[:,0]))\n",
    "# print('2ndColMean:', np.nanmean(data[:,1]))\n",
    "# print('3thColMean:', np.nanmean(data[:,2]))\n",
    "# print('4thColMean:', np.nanmean(data[:,3]))\n",
    "\n",
    "display(mini := np.nanmin(data))\n",
    "Nixs = np.argwhere(np.isnan(data))\n",
    "for ni in Nixs:\n",
    "    data[ni[0], ni[1]] = mini\n",
    "data\n",
    "np.mean(data, axis=0).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-56, -19, -15,   4,  12,  22,  23,  27,  31,  34,  45,  56,  56,  61,  70,  90])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([-56, -19, -15,   4,  12,  22,  23,  27,  31,  34,  45,  56,  56,  61,  70,  90])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Q4\n",
    "A = np.array([[12,34,-15,56], [23,22,90,-56], [4,-19,27,31], [45,56,61,70]])\n",
    "display(np.sort(A, axis=None))\n",
    "display(np.sort(np.reshape(A, (16,))))\n",
    "#                     np.sort(A).reshape(16,)     # BAD\n",
    "# A.sort(axis=None)\n",
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5\n",
    "for null_pos in np.argwhere(np.isnan(data)):\n",
    "    # dataN[null_pos[0], null_pos[1]] = 1\n",
    "    pass\n",
    "\n",
    "np.isnan(dataN).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['e_1', 'e_4', 'e_2', 'e_3'], dtype='<U11')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([['e_1', '1'],\n",
       "       ['e_4', '2'],\n",
       "       ['e_2', '2'],\n",
       "       ['e_3', '3']], dtype='<U11')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[['e_1', '1'],\n",
       "        ['e_4', '2'],\n",
       "        ['e_2', '2'],\n",
       "        ['e_3', '3']]], dtype='<U11')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q6\n",
    "d = np.array([['e_1', 'e_4', 'e_2', 'e_3'], [1,2,2,3]])\n",
    "d\n",
    "display(d[0,:])\n",
    "display(np.stack((d[0],d[1]), axis=1))\n",
    "np.dstack((d[0],d[1]))\n",
    "# d[0,:] = np.chararray.strip(data[0,:], 'e_')\n",
    "# r_d = np.array((d[0,:],))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Questions - Exercises "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1 \n",
    "dataN0 = np.genfromtxt('Lending-Company-Numeric-Data-NAN.csv',\n",
    "                       delimiter=';',\n",
    "                       skip_header=1)\n",
    "np.isnan(dataN0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3 Change NAN to min\n",
    "# display(c1_min := np.nanmin(dataN[:,0]))      # 1000.0\n",
    "display(c1b_min := np.nanmin(dataN[0:,:1]))\n",
    "print(np.isnan(dataN[0:,:1]).sum())\n",
    "# Imposible change NANs without indices\n",
    "for val in dataN[0:,:1]:\n",
    "    # if val == [np.nan]:\n",
    "    if np.isnan(val):\n",
    "        pass\n",
    "        # print(val)\n",
    "        # print(val, end=' - ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3 2nd col (col[1]) dataN mean -258.55\n",
    "print('1stColMean:', np.nanmean(dataN[:,0]))\n",
    "print('2ndColMean:', np.nanmean(dataN[:,1]))\n",
    "print('3thColMean:', np.nanmean(dataN[:,2]))\n",
    "print('4thColMean:', np.nanmean(dataN[:,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4 Sort a flattened version of the array - diff. alternatives\n",
    "A = np.array([[12,34,-15,56], [23,22,90,-56], [4,-19,27,31], [45,56,61,70]])\n",
    "display(np.sort(A, axis=None))\n",
    "display(np.sort(np.reshape(A, (16,))))\n",
    "#                     np.sort(A).reshape(16,)     # BAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5 Replace NANs with 1 - ELIMINATE NANs from 'dataN'\n",
    "for null_pos in np.argwhere(np.isnan(dataN)):\n",
    "    # dataN[null_pos[0], null_pos[1]] = 1\n",
    "    pass\n",
    "\n",
    "np.isnan(dataN).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. When using the np.sum() function on a boolean array returned by np.isnan(), the result will indicate the total number of missing values in the dataset.\n",
    "- True\n",
    "- Explanation: In NumPy, True can be represented with 1 and False can be represented with 0. Summing the boolean array returned by np.isnan() will count the number of True values, which corresponds to the number of missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Filling missing values with the mean of the column will not change the overall mean of that column.\n",
    "- True\n",
    "- Explanation: Filling missing values with the mean of a column ensures that the overall mean remains unchanged. This method keeps the distribution of data consistent while handling missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. What does the np.where() function do?\n",
    "- It replaces values in an array based on a condition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Setting axis=None in np.sort() on a 2D array will sort the flattened array and return a 1D array.\n",
    "- True "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Which of the following best describes the default behavior of np.sort() when sorting a 2D array?\n",
    "- It sorts each row of the array in ascending order.\n",
    "- Explanation: The default behavior of np.sort() on a 2D array is to sort each row (the last axis) individually in ascending order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. The np.argwhere() function returns the coordinates of all non-zero elements in a NumPy array by\n",
    "- True\n",
    "- Explanation: By default, np.argwhere() checks for non-zero elements in the array and returns their coordinates as indices in a 2D array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. When using np.random.shuffle() the function returns a new array without modifying the original array.\n",
    "- False\n",
    "- Explanation: np.random.shuffle() modifies the array in place, meaning it rearranges the rows of the dataset directly and does not return a new array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. You have a 2D array of float values and you want to cast them into integers. Complete the following code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[1.2, 2.5, 3.1], [4.6, 5.8, 6.9]]) \n",
    "\n",
    "# Convert float values to integers\n",
    "int_data = data.astype(dtype = np.int32) \n",
    "print(int_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some JM - Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. reshape function and method\n",
    "display(A := np.arange(1,7).reshape(2,3))\n",
    "np.reshape(A, (3,2))    # <- Inplace=False\n",
    "display(A)\n",
    "A.reshape(3,2)          # <- Inplace=False\n",
    "B = A.reshape(3,2) \n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. sort function and method\n",
    "display(C := np.arange(6,0,-1).reshape(2,3))\n",
    "display(np.sort(C))\n",
    "display(np.sort(C, axis=1))\n",
    "display(np.sort(C, axis=-1))    # sort rows\n",
    "C\n",
    "display(np.sort(C, axis=0))     # sort cols\n",
    "C\n",
    "display(C.sort())\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting in descending order\n",
    "display(np.flip(np.sort(C)))\n",
    "display(C)\n",
    "-np.sort(-C)\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting letters in descending order\n",
    "lst = [chr(i) for i in range(100, 115)]\n",
    "display(L := np.array(lst).reshape(3,5))\n",
    "display(np.sort(L))\n",
    "np.flip(np.sort(L))\n",
    "# numpy.flip(m, axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True - False element-wise letters\n",
    "display(L)\n",
    "L[0,3] = '' \n",
    "L[1,1] = 0\n",
    "L[2,4] = False\n",
    "display(L)\n",
    "display(L[L == True])\n",
    "display(L[L == False])\n",
    "display(L[L != False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True - False element-wise nums\n",
    "display(R := np.random.randn(15).round(2).reshape(3,5) * 17)\n",
    "R[0,3] = R[1,0] = R[2,4] = 0\n",
    "display(R)\n",
    "display(R[R == True])\n",
    "display(R[R == False])\n",
    "display(R[R != False])\n",
    "display(R[R != True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 .shuffle Gen method, inplace True, axis=0 rows default\n",
    "display(I := np.arange(18).reshape(3,6))\n",
    "\n",
    "from numpy.random import Generator as gen  \n",
    "from numpy.random import PCG64 as pcg \n",
    "\n",
    "array_RG = gen(pcg())\n",
    "array_RG.shuffle(I, axis=0)\n",
    "\n",
    "I\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(I := np.arange(18).reshape(3,6))\n",
    "# np.random.shuffle(I, axis=1)\n",
    "# I\n",
    "# # TypeError: shuffle() got an unexpected keyword argument 'axis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11 .astype() method <- inplace False\n",
    "display(I := np.arange(18).reshape(3,6))\n",
    "display(I)\n",
    "display(I.astype(dtype=str))\n",
    "display(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 13. The truth about the 'same' shape in stacks\n",
    "display(S := np.arange(24).reshape(4,6))\n",
    "display(S2r := S[[-1,-2]])\n",
    "# np.stack((S,S2r)) # ValueError: all input arrays must have the same shape\n",
    "# np.stack((S, S2r), axis=1)    # ValueError:\n",
    "\n",
    "np.vstack((S,S2r))  # OK!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 14. Concatenate - v-h stack <- dimensions\n",
    "display(S := np.arange(24).reshape(4,6))\n",
    "print(show_attr('S'))\n",
    "display(S2r := S[[-1,-2]])\n",
    "print(show_attr('S2r'))\n",
    "display(S2c := S[:,[2,1]])\n",
    "print(show_attr('S2c'))\n",
    "\n",
    "display(concat_r := np.concatenate((S, S2r)))\n",
    "print(show_attr('concat_r'))\n",
    "\n",
    "display(vstack := np.vstack((S, S2r)))\n",
    "print(show_attr('vstack'))\n",
    "\n",
    "display(stack_r := np.stack((S, S)))\n",
    "print(show_attr('stack_r'))\n",
    "\n",
    "display(concat_c := np.concatenate((S, S2c), axis=1))\n",
    "print(show_attr('concat_c'))\n",
    "\n",
    "display(hstack := np.hstack((S, S2c)))\n",
    "print(show_attr('hstack'))\n",
    "\n",
    "display(stack_c := np.stack((S, S), axis=1))\n",
    "print(show_attr('stack_c'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
